{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1",
      "metadata": {
        "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1"
      },
      "source": [
        "# 6 WorkFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c586e3-ed7d-44b2-92a0-f19669f06940",
      "metadata": {
        "id": "29c586e3-ed7d-44b2-92a0-f19669f06940"
      },
      "source": [
        "### 6.1 Objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fff8327-10ed-4b11-bbee-f1c3f357d123",
      "metadata": {
        "id": "6fff8327-10ed-4b11-bbee-f1c3f357d123"
      },
      "source": [
        "Presentar un workflow/pipeline completo al que los estudiantes deberán enriquecer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2  Seteo del ambiente en Google Colab"
      ],
      "metadata": {
        "id": "PX0qg_c0yqob"
      },
      "id": "PX0qg_c0yqob"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ],
      "id": "NGY7H9xza7Zr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ],
      "id": "7PupIBNba7Zr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs"
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ],
      "id": "9LpZCst5a7Zs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "*   Bajar el **dataset_historico** al Google Drive y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ],
      "id": "JYC_F-wla7Zs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/dm\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "webfiles=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/\"\n",
        "destino_local=\"/content/datasets\"\n",
        "destino_bucket=\"/content/buckets/b1/datasets\"\n",
        "\n",
        "\n",
        "archivo=\"dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $destino_bucket/$archivo; then\n",
        "  wget  $webfiles/$archivo  -O $destino_bucket/$archivo\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $destino_local/$pequeno; then\n",
        "  cp  $destino_bucket/$archivo  $destino_local/$archivo\n",
        "fi\n",
        "\n",
        "#-------\n",
        "\n",
        "archivo=\"gerencial_competencia_2025.csv.gz\"\n",
        "\n",
        "if ! test -f $destino_bucket/$archivo; then\n",
        "  wget  $webfiles/$archivo  -O $destino_bucket/$archivo\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $destino_local/$pequeno; then\n",
        "  cp  $destino_bucket/$archivo  $destino_local/$archivo\n",
        "fi\n"
      ],
      "id": "XWLelftXa7Zt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3  Workflow"
      ],
      "metadata": {
        "id": "oSKhZRToy2F7"
      },
      "id": "oSKhZRToy2F7"
    },
    {
      "cell_type": "markdown",
      "id": "85171302-a2d6-48cb-b9b2-8d839a276859",
      "metadata": {
        "id": "85171302-a2d6-48cb-b9b2-8d839a276859"
      },
      "source": [
        "## Inicializacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ],
      "id": "eSU5vi00CPRS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8dySimCPRT"
      },
      "source": [
        "limpio el ambiente de R"
      ],
      "id": "Zq8dySimCPRT"
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "EL8wdHaUs59K"
      },
      "id": "EL8wdHaUs59K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iE0U4_WCPRT"
      },
      "outputs": [],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ],
      "id": "1iE0U4_WCPRT"
    },
    {
      "cell_type": "code",
      "source": [
        "require(\"data.table\")\n",
        "\n",
        "if( !require(\"R.utils\")) install.packages(\"R.utils\")\n",
        "require(\"R.utils\")"
      ],
      "metadata": {
        "id": "atmIUEUNUrK5"
      },
      "id": "atmIUEUNUrK5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parametros\n",
        "Si es gerente, no cambie nada\n",
        "<br>Si es Analista, cambie el nombre del dataset"
      ],
      "metadata": {
        "id": "BsxZ_ONyj9L_"
      },
      "id": "BsxZ_ONyj9L_"
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$semilla_primigenia <- 102191\n",
        "\n",
        "PARAM$experimento <- 6300\n",
        "PARAM$dataset <- \"gerencial_competencia_2025.csv.gz\""
      ],
      "metadata": {
        "id": "peRH7ySLCPRV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "peRH7ySLCPRV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carpeta del Experimento"
      ],
      "metadata": {
        "id": "NoJbKo_4NG8A"
      },
      "id": "NoJbKo_4NG8A"
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"WF\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "1gZD6ZMvCPRV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1gZD6ZMvCPRV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3.1   Preprocesamiento del dataset"
      ],
      "metadata": {
        "id": "YVKBfLtkR8SO"
      },
      "id": "YVKBfLtkR8SO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.1.1  DT incorporar dataset"
      ],
      "metadata": {
        "id": "cr3K0RPVRjq6"
      },
      "id": "cr3K0RPVRjq6"
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(paste0(\"/content/datasets/\", PARAM$dataset))"
      ],
      "metadata": {
        "id": "Xi0emX2ECPRV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Xi0emX2ECPRV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.1.2  CA  Catastrophe Analysis\n",
        "Se intentan reparar las variables que para un mes están con todos los valores en cero."
      ],
      "metadata": {
        "id": "MWuPzK3nSLY3"
      },
      "id": "MWuPzK3nSLY3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método que se utiliza es **Machine Learning** se asigna NA also valores, si ha leido bien, es la \"anti imputación de valores faltantes\"\n",
        "<br> Usted podrá aplicar aquí otros métodos"
      ],
      "metadata": {
        "id": "UAI16-yCVcBS"
      },
      "id": "UAI16-yCVcBS"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[ foto_mes==202006, internet:=NA]\n",
        "dataset[ foto_mes==202006, mrentabilidad:=NA]\n",
        "dataset[ foto_mes==202006, mrentabilidad_annual:=NA]\n",
        "dataset[ foto_mes==202006, mcomisiones:=NA]\n",
        "dataset[ foto_mes==202006, mactivos_margen:=NA]\n",
        "dataset[ foto_mes==202006, mpasivos_margen:=NA]\n",
        "dataset[ foto_mes==202006, mcuentas_saldo:=NA]\n",
        "dataset[ foto_mes==202006, ctarjeta_visa_transacciones:=NA]\n",
        "dataset[ foto_mes==202006, mtarjeta_visa_consumo:=NA]\n",
        "dataset[ foto_mes==202006, mtarjeta_master_consumo:=NA]\n",
        "dataset[ foto_mes==202006, ccallcenter_transacciones:=NA]\n",
        "dataset[ foto_mes==202006, chomebanking_transacciones:=NA]\n",
        "dataset[ foto_mes==202006, chomebanking_transacciones:=NA]"
      ],
      "metadata": {
        "id": "sTmliO_FXv9E"
      },
      "id": "sTmliO_FXv9E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.1.3  DR  Data Drifting\n",
        "Se intenta corregir el data drifting, quizas ajustando por IPC ...\n",
        "<br>Esta parte podrá ser abordada por todos los Analistas y también la Gerenciapero se decide pedagogicamente no incluirla en esta primer version para reducir la carga cognitiva"
      ],
      "metadata": {
        "id": "-4NiANYFSYHG"
      },
      "id": "-4NiANYFSYHG"
    },
    {
      "cell_type": "code",
      "source": [
        "# sin codigo en esta primera version del workflow"
      ],
      "metadata": {
        "id": "L85A2lwKSe3k"
      },
      "id": "L85A2lwKSe3k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.1.3  FE_intra_manual Feature Engineering intra-mes\n",
        "\n",
        "Agrego campos nuevos dentro del mismo mes, SIN considerar la historia."
      ],
      "metadata": {
        "id": "7sppIDYeSn5X"
      },
      "id": "7sppIDYeSn5X"
    },
    {
      "cell_type": "code",
      "source": [
        "# esta funcion atributos presentes existe debido a que las modalidades poseen datasets con distinta cantidad de campos\n",
        "atributos_presentes <- function( patributos )\n",
        "{\n",
        "  atributos <- unique( patributos )\n",
        "  comun <- intersect( atributos, colnames(dataset) )\n",
        "\n",
        "  return(  length( atributos ) == length( comun ) )\n",
        "}\n",
        "\n",
        "# el mes 1,2, ..12\n",
        "if( atributos_presentes( c(\"foto_mes\") ))\n",
        "  dataset[, kmes := foto_mes %% 100]\n",
        "\n",
        "# variable extraida de una tesis de maestria de Irlanda\n",
        "if( atributos_presentes( c(\"mpayroll\", \"cliente_edad\") ))\n",
        "  dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n"
      ],
      "metadata": {
        "id": "qrqf3j3_St3p"
      },
      "id": "qrqf3j3_St3p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizo las columas del dataset a esta etapa\n",
        "colnames(dataset)"
      ],
      "metadata": {
        "id": "iC4viwOdY5Kp"
      },
      "id": "iC4viwOdY5Kp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9682b4ca-3ab3-4bbc-a36a-b185361e6b6b",
      "metadata": {
        "id": "9682b4ca-3ab3-4bbc-a36a-b185361e6b6b"
      },
      "source": [
        "#### 6.3.1.4  FE_rf Feature Engineering de nuevas variables a partir de hojas de Random Forest\n",
        "\n",
        "Esto se mostrará unicamente a la *modalidad Analista Sr*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# No se implementa Feature Engineering a partir de Random Forest"
      ],
      "metadata": {
        "id": "ljA3h0jOcciP"
      },
      "id": "ljA3h0jOcciP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.1.5  FEhist Feature Engineering historico\n",
        "\n",
        "El Fature Engineering Histórico es la etapa que más aporta a la ganancia final, ya que enriquece cada registro del dataset con su historia."
      ],
      "metadata": {
        "id": "XaRBjQj8ZRUZ"
      },
      "id": "XaRBjQj8ZRUZ"
    },
    {
      "cell_type": "markdown",
      "id": "cfe3b8cf-0707-4512-92e7-c1407bb3f73b",
      "metadata": {
        "id": "cfe3b8cf-0707-4512-92e7-c1407bb3f73b"
      },
      "source": [
        "Para cada campo del dataset original (*)\n",
        "se crean lo siguientes campos de a partir de la historia\n",
        "* lag1  lags de orden 1\n",
        "* delta1  =  valor actual - lag1\n",
        "* lag2  lags de orden 2\n",
        "* delta2  = valor actual - lag2\n",
        "\n",
        "\n",
        "(*) Excepto para los campos  <numero_de_cliente,  foto_mes,  clase_ternaria>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7850b948-827d-4a2a-b4d3-a5e459b47c11",
      "metadata": {
        "id": "7850b948-827d-4a2a-b4d3-a5e459b47c11"
      },
      "outputs": [],
      "source": [
        "# Feature Engineering Historico\n",
        "\n",
        "# todo es lagueable, menos la primary key y la clase\n",
        "cols_lagueables <- copy( setdiff(\n",
        "    colnames(dataset),\n",
        "    c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
        ") )\n",
        "\n",
        "# https://rdrr.io/cran/data.table/man/shift.html\n",
        "\n",
        "# lags de orden 1\n",
        "dataset[,\n",
        "    paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
        "    by = numero_de_cliente,\n",
        "    .SDcols = cols_lagueables\n",
        "]\n",
        "\n",
        "# lags de orden 2\n",
        "dataset[,\n",
        "    paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
        "    by = numero_de_cliente,\n",
        "    .SDcols = cols_lagueables\n",
        "]\n",
        "\n",
        "# agrego los delta lags\n",
        "for (vcol in cols_lagueables)\n",
        "{\n",
        "    dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
        "    dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cea690d9-ece9-4852-a5e2-f337c31b6721",
      "metadata": {
        "id": "cea690d9-ece9-4852-a5e2-f337c31b6721"
      },
      "source": [
        "Verificacion de los campos recien creados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f772896b-595a-47d4-8905-c15304ac9452",
      "metadata": {
        "id": "f772896b-595a-47d4-8905-c15304ac9452"
      },
      "outputs": [],
      "source": [
        "ncol(dataset)\n",
        "colnames(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.3.1.6  FEhist Reduccion dimensionalidad con canaritos\n",
        "\n",
        "Esta etapa solo se mostrará a la *modalidad Anlista Sr* por algun canal secreto de forma de no confundir a los *Analista Jr*  nni distraer con detalles operativos a la estratégica *Modalidad Gerencial*"
      ],
      "metadata": {
        "id": "l8mKij0XaDY0"
      },
      "id": "l8mKij0XaDY0"
    },
    {
      "cell_type": "code",
      "source": [
        "# No se implementa la reduccion de la dimensionalidad con canaritos"
      ],
      "metadata": {
        "id": "QrmnPtlBcEgx"
      },
      "id": "QrmnPtlBcEgx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cf91ea5e-3341-4afb-8d05-cc4923d3d1e1",
      "metadata": {
        "id": "cf91ea5e-3341-4afb-8d05-cc4923d3d1e1"
      },
      "source": [
        "### 6.3.2 Modelado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "526048e4-8cf2-4023-bd2d-a70e4e9ff157",
      "metadata": {
        "id": "526048e4-8cf2-4023-bd2d-a70e4e9ff157"
      },
      "source": [
        "#### 6.3.2.1 Training Strategy\n",
        "\n",
        "Esta etapa de Workflow de  Training Strategy esta pensada para la *Modalidad Gerencial* que posee el dataset de [202005, 202109]\n",
        "<br> Si usted es un Analista, posee el periodo de [201901, 202109] y deberá experimentar en que meses le conviene experimentar\n",
        "\n",
        "<br> A la *Modalidad Gerencial* no se le complicada la vida con el undersampling de los continua, por eso PARAM$trainingstrategy$training_pct <- 1.0\n",
        "<br> Sin embargo, si usted es  *Analista SR* posee un dataset 50 veces ( filas x columnas) más grande que la *Modalidad Gerencial*  y por un tema de velocidad y experimentación más rápida puede llegar a necesitar activar el undersampling de la clase mayoritaria, a pesar de estar corriendo en Google Cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16bc1c1-b3ea-43ca-9d3c-53f8f9ab8ec1",
      "metadata": {
        "id": "f16bc1c1-b3ea-43ca-9d3c-53f8f9ab8ec1"
      },
      "source": [
        "Se hace una estrategia de entrenamiento muy sencilla, tomando todos los meses posibles, SIN eliminar nada x pandemia ni por ningun otro motivo\n",
        "\n",
        "* future = 202109  obviamente completo\n",
        "\n",
        "* final_train =  [ 202005, 202107 ]  SIN undersampling\n",
        "\n",
        "* training\n",
        "   * testing = NO HAY\n",
        "   * validation =  202107   completo, sin undersampling\n",
        "   * training = [ 202005, 202106 ]  donde se consideran el 100% de los CONTINUA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c9c0a42-ba58-4264-8566-091a6161716f",
      "metadata": {
        "id": "2c9c0a42-ba58-4264-8566-091a6161716f"
      },
      "outputs": [],
      "source": [
        "PARAM$trainingstrategy$validate <- c(202107)\n",
        "\n",
        "PARAM$trainingstrategy$training <- c(\n",
        "  202106, 202105, 202104, 202103, 202102, 202101,\n",
        "  202012, 202011, 202010, 202009, 202008, 202007,\n",
        "  202006, 202005\n",
        ")\n",
        "\n",
        "PARAM$trainingstrategy$training_pct <- 1.0\n",
        "\n",
        "\n",
        "PARAM$trainingstrategy$positivos <- c( \"BAJA+1\", \"BAJA+2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seteo la clase01   1={BAJA+1, BAJA+2}   0={CONTINUA}\n",
        "dataset[, clase01 := ifelse( clase_ternaria %in% PARAM$trainingstrategy$positivos, 1, 0 )]"
      ],
      "metadata": {
        "id": "tv_trHWAj4a8"
      },
      "id": "tv_trHWAj4a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos en los que se entrena\n",
        "campos_buenos <- copy( setdiff(\n",
        "    colnames(dataset), c(\"clase_ternaria\",\"clase01\",\"azar\"))\n",
        ")"
      ],
      "metadata": {
        "id": "Ud_XDKSIj8f_"
      },
      "id": "Ud_XDKSIj8f_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparo para que se puede hacer undersampling de los CONTINUA\n",
        "#  solamente por un tema de VELOCIDAD\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset[, azar:=runif(nrow(dataset))]\n",
        "\n",
        "# undersampling de los CONTINUA\n",
        "dataset[, fold_train :=  foto_mes %in%  PARAM$trainingstrategy$training &\n",
        "    (clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\") |\n",
        "     azar < PARAM$trainingstrategy$training_pct ) ]\n",
        "\n",
        "\n",
        "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[fold_train == TRUE, campos_buenos, with = FALSE]),\n",
        "  label= dataset[fold_train == TRUE, clase01],\n",
        "  free_raw_data= TRUE\n",
        ")"
      ],
      "metadata": {
        "id": "rFKgZZPSj_Pa"
      },
      "id": "rFKgZZPSj_Pa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datos de validation\n",
        "dvalidate <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[foto_mes %in% PARAM$trainingstrategy$validate, campos_buenos, with = FALSE]),\n",
        "  label= dataset[foto_mes %in% PARAM$trainingstrategy$validate, clase01],\n",
        "  free_raw_data= TRUE\n",
        ")\n",
        "\n",
        "nrow(dvalidate)"
      ],
      "metadata": {
        "id": "B3yo98kQkHcP"
      },
      "id": "B3yo98kQkHcP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "28e8f788-551c-4e50-9029-302ac0834287",
      "metadata": {
        "id": "28e8f788-551c-4e50-9029-302ac0834287"
      },
      "source": [
        "####  6.3.2.2. Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf5fc836-e222-4aeb-a6a8-157346895ef7",
      "metadata": {
        "id": "bf5fc836-e222-4aeb-a6a8-157346895ef7"
      },
      "source": [
        "* Clase binaria que se optimiza :  positivos = [ BAJA+1, BAJA+2 ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "885c03b5-77bc-4510-a930-0d1f14b52ffb",
      "metadata": {
        "id": "885c03b5-77bc-4510-a930-0d1f14b52ffb"
      },
      "source": [
        "* Metrica que se optimiza **AUC** Area Under Curve de la  ROC Curve\n",
        "\n",
        "es muy importante notar que intencionalmente  **NO** se está optimizando la funcion de ganancia del problema"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e6f95c-66ef-4ab9-9ba3-fcc099816704",
      "metadata": {
        "id": "b7e6f95c-66ef-4ab9-9ba3-fcc099816704"
      },
      "source": [
        "* Cantidad de iteraciones inteligentes de la Optimizacion Bayesiana = **10**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe047a87-e2d0-4418-97dd-0a881e66d73a",
      "metadata": {
        "id": "fe047a87-e2d0-4418-97dd-0a881e66d73a"
      },
      "source": [
        "* Parametros no default, fijos de LightGBM que no se optimizan\n",
        "  * max_bin = 31 , Alienigenas Ancestrales contruyeron las pirámides y dejaron a la humanidad en un jeroglifico  *max_bin=31*\n",
        "  * feature_fraction = 0.5  para poner algo que generalmente no falla\n",
        "  * learning_rate = 0.03  para que aprenda lento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7da08e-fe57-4681-beff-11fe963116bd",
      "metadata": {
        "id": "1e7da08e-fe57-4681-beff-11fe963116bd"
      },
      "source": [
        "* Parametros que se optimizan en la Bayesian Optimization\n",
        "  * num_leaves  [8, 256]\n",
        "  * min_data_in_leaf  [8, 8192]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paquetes necesarios para la Bayesian Optimization\n",
        "if(!require(\"DiceKriging\")) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if(!require(\"mlrMBO\")) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ],
      "metadata": {
        "id": "34V6y4GetKq_"
      },
      "id": "34V6y4GetKq_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición de la Bayesian Optimization\n",
        "<br> Si se desea optimizar un hiperparámetro que esta como fijo, debe QUITARSE de param_fijos y agregarse a PARAM$hipeparametertuning$hs"
      ],
      "metadata": {
        "id": "UFbDSYtH0TTT"
      },
      "id": "UFbDSYtH0TTT"
    },
    {
      "cell_type": "code",
      "source": [
        "# valor ridiculamente bajo para que corra rapido en el aula y no molestar a la *Modalidad Gerencial*\n",
        "PARAM$hipeparametertuning$num_interations <- 10\n",
        "\n",
        "# parametros fijos del LightGBM\n",
        "PARAM$lgbm$param_fijos <- list(\n",
        "  objective= \"binary\",\n",
        "  metric= \"auc\",\n",
        "  first_metric_only= TRUE,\n",
        "  boost_from_average= TRUE,\n",
        "  feature_pre_filter= FALSE,\n",
        "  verbosity= -100,\n",
        "  force_row_wise= TRUE, # para evitar warning\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "  max_bin= 31,\n",
        "  learning_rate= 0.03,\n",
        "  feature_fraction= 0.5,\n",
        "  num_iterations= 2048,  # valor grande, lo limita early_stopping_rounds\n",
        "  early_stopping_rounds= 200\n",
        ")\n",
        "\n",
        "PARAM$hipeparametertuning$hs <- makeParamSet(\n",
        "  makeIntegerParam(\"num_leaves\", lower = 2L, upper = 256L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower = 2L, upper = 8192L)\n",
        ")"
      ],
      "metadata": {
        "id": "5Uag3XGHqrfZ"
      },
      "id": "5Uag3XGHqrfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función \"señora caja negra\"  que es llamada para verificar la realidad por la Bayesian Optimization"
      ],
      "metadata": {
        "id": "FEa1UuuAz4yj"
      },
      "id": "FEa1UuuAz4yj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c10f535-8d90-47d1-ac3d-9b4c24ec21d2",
      "metadata": {
        "id": "2c10f535-8d90-47d1-ac3d-9b4c24ec21d2"
      },
      "outputs": [],
      "source": [
        "# En  x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en validate del modelo entrenado\n",
        "#  en el parametro x llegan los hiperparámetros que se estan optimizando\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelo_train <- lgb.train(\n",
        "    data= dtrain,\n",
        "    valids= list(valid = dvalidate),\n",
        "    eval= \"auc\",\n",
        "    param= param_completo,\n",
        "    verbose= -100\n",
        "  )\n",
        "\n",
        "  # recupero la AUC en validation\n",
        "  AUC <- modelo_train$record_evals$valid$auc$eval[[modelo_train$best_iter]]\n",
        "\n",
        "  # esta es la forma de devolver un parametro extra\n",
        "  attr(AUC, \"extras\") <- list(\"num_iterations\"= modelo_train$best_iter)\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelo_train)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "267a35d4-adaf-4271-a875-3864111333b7",
      "metadata": {
        "id": "267a35d4-adaf-4271-a875-3864111333b7"
      },
      "source": [
        "seteo de la Bayesian Optimization (complejo)\n",
        "<br> copiado y pegado de la documentación de la librería"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43c2a92d-1041-46b8-bff2-47297f209ed2",
      "metadata": {
        "id": "43c2a92d-1041-46b8-bff2-47297f209ed2"
      },
      "outputs": [],
      "source": [
        "configureMlr(show.learner.output = FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "    fn= EstimarGanancia_AUC_lightgbm, # la funcion que voy a maximizar\n",
        "    minimize= FALSE, # estoy Maximizando AUC\n",
        "    noisy= FALSE,\n",
        "    par.set= PARAM$hipeparametertuning$hs,\n",
        "    has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "    save.on.disk.at.time= 600,\n",
        "    save.file.path= \"HT.RDATA\"\n",
        ")\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "    ctrl,\n",
        "    iters= PARAM$hipeparametertuning$num_interations  # cantidad de iteraciones inteligentes\n",
        ")\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales\n",
        "#   los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
        "\n",
        "# mas configuraciones\n",
        "surr.km <- makeLearner(\n",
        "    \"regr.km\",\n",
        "    predict.type= \"se\",\n",
        "    covtype= \"matern3_2\",\n",
        "    control= list(trace = TRUE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c1e5645-d26f-4923-a53f-f30471a4c4e8",
      "metadata": {
        "id": "6c1e5645-d26f-4923-a53f-f30471a4c4e8"
      },
      "source": [
        "Corrida de la Bayesian Optimization,  aqui se hace el trabajo pesado\n",
        "<br> por favor no se asuste con los warnings que pudieran aparecer\n",
        "\n",
        "Si corrío a medias y llegó a las iteraciones inteligentes, en el archivo binario HT.RDATA quedó lo ya procesado y es utilizado para retomar la corrida desde lo último que llegó a grabar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f8cab3f-c7e2-4802-bfd1-5ad509922a4e",
      "metadata": {
        "scrolled": true,
        "id": "1f8cab3f-c7e2-4802-bfd1-5ad509922a4e"
      },
      "outputs": [],
      "source": [
        "# inicio la optimizacion bayesiana\n",
        "\n",
        "if (!file.exists(\"HT.RDATA\")) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(\"HT.RDATA\") # retomo en caso que ya exista\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36307612-964f-4df3-907a-1bc3c095f178",
      "metadata": {
        "id": "36307612-964f-4df3-907a-1bc3c095f178"
      },
      "source": [
        "la bayesian optimization ha corrido, extraigo los mejores hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c061a2a-3341-4006-a154-c95bb6cfd407",
      "metadata": {
        "id": "8c061a2a-3341-4006-a154-c95bb6cfd407"
      },
      "outputs": [],
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y, -num_iterations)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file=\"BO_log.txt\",\n",
        "  sep=\"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  list(num_leaves, min_data_in_leaf, num_iterations)\n",
        "]\n",
        "\n",
        "print(PARAM$out$lgbm$mejores_hiperparametros)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddb554cb-1d96-4f6b-ae1c-c9a076f8dbdc",
      "metadata": {
        "id": "ddb554cb-1d96-4f6b-ae1c-c9a076f8dbdc"
      },
      "source": [
        "### 6.3.3 Produccion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c39492c3-756f-47a5-8747-93ade8275306",
      "metadata": {
        "id": "c39492c3-756f-47a5-8747-93ade8275306"
      },
      "source": [
        "#### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
      ],
      "metadata": {
        "id": "xhKi_G_sYQqq"
      },
      "id": "xhKi_G_sYQqq"
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$trainingstrategy$final_train <- c( 202107,\n",
        "  202106, 202105, 202104, 202103, 202102, 202101,\n",
        "  202012, 202011, 202010, 202009, 202008, 202007,\n",
        "  202006, 202005\n",
        ")\n",
        "\n",
        "dataset[, fold_final_train := foto_mes %in% PARAM$trainingstrategy$final_train ]\n",
        "\n",
        "# creo el dfinal_train en formato  LightGBM\n",
        "dfinal_train <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[fold_final_train == TRUE, campos_buenos, with= FALSE]),\n",
        "  label= dataset[fold_final_train == TRUE, clase01],\n",
        "  free_raw_data= TRUE\n",
        ")\n",
        "\n",
        "nrow( dfinal_train) # verifico el tamaño"
      ],
      "metadata": {
        "id": "qyHfS_X0zd7o"
      },
      "id": "qyHfS_X0zd7o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final Training Hyperparameters"
      ],
      "metadata": {
        "id": "HATRyklxYUpT"
      },
      "id": "HATRyklxYUpT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b9f33c-e0a0-4ea6-8169-4a6180cc5d01",
      "metadata": {
        "id": "d6b9f33c-e0a0-4ea6-8169-4a6180cc5d01"
      },
      "outputs": [],
      "source": [
        "# uno los parametros fijos y los mejores encontrados de los variables\n",
        "fijos <- copy(PARAM$lgbm$param_fijos)\n",
        "\n",
        "# quito lo que optimice en la Bayesian Optimization\n",
        "fijos$num_iterations <- NULL\n",
        "fijos$early_stopping_rounds <- NULL\n",
        "\n",
        "# agrego a los hiperparametros fijos los que encontre con la Bayesian Optimization\n",
        "param_final <- c(fijos, PARAM$out$lgbm$mejores_hiperparametros)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05d3494f-0401-4f3e-9b69-f488a737879d",
      "metadata": {
        "id": "05d3494f-0401-4f3e-9b69-f488a737879d"
      },
      "source": [
        "##### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa239848-1c28-4ee5-984a-073903b4b279",
      "metadata": {
        "id": "fa239848-1c28-4ee5-984a-073903b4b279"
      },
      "outputs": [],
      "source": [
        "final_model <- lgb.train(\n",
        "  data= dfinal_train,\n",
        "  param= param_final,\n",
        "  verbose= -100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "\n",
        "lgb.save(final_model, \"modelo.txt\")"
      ],
      "metadata": {
        "id": "RC1ju-5MZN5s"
      },
      "id": "RC1ju-5MZN5s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(final_model))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite( tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "VEpv4RYOZHTU"
      },
      "id": "VEpv4RYOZHTU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7ea225b3-ce02-42e2-8330-b10ed250d172",
      "metadata": {
        "id": "7ea225b3-ce02-42e2-8330-b10ed250d172"
      },
      "source": [
        "#### Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "164981bb-f4c1-4228-8bc9-32e58a383c05",
      "metadata": {
        "id": "164981bb-f4c1-4228-8bc9-32e58a383c05"
      },
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$trainingstrategy$future <- c(202109)\n",
        "\n",
        "dfuture <- dataset[ foto_mes %in% PARAM$trainingstrategy$future ]"
      ],
      "metadata": {
        "id": "eJ7RbT271v-R"
      },
      "id": "eJ7RbT271v-R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ca61c8-fa24-4ce5-8be1-323aca018e8f",
      "metadata": {
        "id": "88ca61c8-fa24-4ce5-8be1-323aca018e8f"
      },
      "outputs": [],
      "source": [
        "# aplico final_model   a dfuture\n",
        "\n",
        "prediccion <- predict(\n",
        "  final_model,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tabla Prediccion"
      ],
      "metadata": {
        "id": "79u0ZvjJZblE"
      },
      "id": "79u0ZvjJZblE"
    },
    {
      "cell_type": "code",
      "source": [
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := prediccion]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "#  me va a ser util para hacer Ensembles de modelos\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "TB6aerGDZeTo"
      },
      "id": "TB6aerGDZeTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8412d838-5bd5-454e-b3a9-5eaa18d80a50",
      "metadata": {
        "id": "8412d838-5bd5-454e-b3a9-5eaa18d80a50"
      },
      "source": [
        "#### Kaggle Competition Submit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55970cb6-856a-46e3-a893-7f36b8352b8e",
      "metadata": {
        "id": "55970cb6-856a-46e3-a893-7f36b8352b8e"
      },
      "source": [
        "Genero las salidas y hago los submits a Kaggle\n",
        "<br>El notebook esta preparado para la Modalidad Gerencial, los analistas deben hacer cambios.\n",
        "<br> Los analistas deben cambiar **competencia** a SU competencia  \"data-mining-analista-jr-2025-a\"   o  la original \"data-mining-analista-sr-2025-a\"  para los Senior\n",
        "<br> Los cortes  dependen de la cantidad de registros, multiplicar por 2 para los Analistas Jr y por 10 para los Analista Sr\n",
        "\n",
        "Los Analista Sr luego de meditar cuidadosamente reducirán la cantidad de cortes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5fa2439-b0e9-49e0-a861-71d7315d6e1c",
      "metadata": {
        "id": "e5fa2439-b0e9-49e0-a861-71d7315d6e1c"
      },
      "outputs": [],
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "PARAM$kaggle$competencia <- \"data-mining-gerencial-2025-b\"\n",
        "PARAM$kaggle$cortes <- seq(800, 1300, by = 50)\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$kaggle$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  # subida a Kaggle, armo la linea de comando\n",
        "  comando <- \"kaggle competitions submit\"\n",
        "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
        "  arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
        "  \"  semilla=\", PARAM$semilla_primigenia,\n",
        "    \"'\" )\n",
        "\n",
        "  linea <- paste( comando, competencia, arch, mensaje)\n",
        "\n",
        "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
        "  cat(salida, \"\\n\")\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo los parametros\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ],
      "metadata": {
        "id": "C94tK-xid6p2"
      },
      "id": "C94tK-xid6p2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb",
      "metadata": {
        "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb"
      },
      "outputs": [],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}