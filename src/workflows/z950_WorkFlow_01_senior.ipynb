{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1",
      "metadata": {
        "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1"
      },
      "source": [
        "# 9 WorkFlow Analista Senior"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c586e3-ed7d-44b2-92a0-f19669f06940",
      "metadata": {
        "id": "29c586e3-ed7d-44b2-92a0-f19669f06940"
      },
      "source": [
        "### 9.5 Objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fff8327-10ed-4b11-bbee-f1c3f357d123",
      "metadata": {
        "id": "6fff8327-10ed-4b11-bbee-f1c3f357d123"
      },
      "source": [
        "Presentar un workflow/pipeline completo al que los estudiantes deberán\n",
        "enriquecer\n",
        "<br>El Analista Sr corre sus scripts en máquinas virtuales de al menos 128 GB de RAM en Toronto, creando una virtual machine para cada corrida.\n",
        "<br>Estas virtual machines se auto-suicidarán a los 30 minutos de haber terminado de procesar."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.7  Workflow"
      ],
      "metadata": {
        "id": "oSKhZRToy2F7"
      },
      "id": "oSKhZRToy2F7"
    },
    {
      "cell_type": "markdown",
      "id": "85171302-a2d6-48cb-b9b2-8d839a276859",
      "metadata": {
        "id": "85171302-a2d6-48cb-b9b2-8d839a276859"
      },
      "source": [
        "## Inicializacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ],
      "id": "eSU5vi00CPRS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8dySimCPRT"
      },
      "source": [
        "limpio el ambiente de R"
      ],
      "id": "Zq8dySimCPRT"
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "EL8wdHaUs59K"
      },
      "id": "EL8wdHaUs59K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iE0U4_WCPRT"
      },
      "outputs": [],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ],
      "id": "1iE0U4_WCPRT"
    },
    {
      "cell_type": "code",
      "source": [
        "require(\"data.table\")\n",
        "\n",
        "if( !require(\"R.utils\")) install.packages(\"R.utils\")\n",
        "require(\"R.utils\")"
      ],
      "metadata": {
        "id": "atmIUEUNUrK5"
      },
      "id": "atmIUEUNUrK5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parametros\n"
      ],
      "metadata": {
        "id": "BsxZ_ONyj9L_"
      },
      "id": "BsxZ_ONyj9L_"
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$semilla_primigenia <- 102191\n",
        "\n",
        "PARAM$experimento <- 9500\n",
        "PARAM$dataset <- \"analistasr_competencia_2025.csv.gz\""
      ],
      "metadata": {
        "id": "peRH7ySLCPRV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "peRH7ySLCPRV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carpeta del Experimento"
      ],
      "metadata": {
        "id": "NoJbKo_4NG8A"
      },
      "id": "NoJbKo_4NG8A"
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"WF\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "1gZD6ZMvCPRV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1gZD6ZMvCPRV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.7.1   Preprocesamiento del dataset"
      ],
      "metadata": {
        "id": "YVKBfLtkR8SO"
      },
      "id": "YVKBfLtkR8SO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9.7.1.1  DT incorporar dataset"
      ],
      "metadata": {
        "id": "cr3K0RPVRjq6"
      },
      "id": "cr3K0RPVRjq6"
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(paste0(\"/content/datasets/\", PARAM$dataset))"
      ],
      "metadata": {
        "id": "Xi0emX2ECPRV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Xi0emX2ECPRV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9.7.1.2  CA  Catastrophe Analysis\n",
        "Se intentan reparar las variables que para un mes están con todos los valores en cero."
      ],
      "metadata": {
        "id": "MWuPzK3nSLY3"
      },
      "id": "MWuPzK3nSLY3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método que se utiliza es **Machine Learning** se asigna NA also valores, si ha leido bien, es la \"anti imputación de valores faltantes\"\n",
        "<br> Usted podrá aplicar aquí otros métodos"
      ],
      "metadata": {
        "id": "UAI16-yCVcBS"
      },
      "id": "UAI16-yCVcBS"
    },
    {
      "cell_type": "code",
      "source": [
        "if( !require(\"mice\")) install.packages(\"mice\", repos = \"http://cran.us.r-project.org\")\n",
        "require(\"mice\")"
      ],
      "metadata": {
        "id": "JB9nRyNKNBzy"
      },
      "id": "JB9nRyNKNBzy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escrito por alumnos de  Universidad Austral  Rosario\n",
        "\n",
        "Corregir_MICE <- function(pcampo, pmeses) {\n",
        "\n",
        "  meth <- rep(\"\", ncol(dataset))\n",
        "  names(meth) <- colnames(dataset)\n",
        "  meth[names(meth) == pcampo] <- \"sample\"\n",
        "\n",
        "  # llamada a mice  !\n",
        "  imputacion <- mice(dataset,\n",
        "    method = meth,\n",
        "    maxit = 5,\n",
        "    m = 1,\n",
        "    seed = 7)\n",
        "\n",
        "  tbl <- mice::complete(dataset)\n",
        "\n",
        "  dataset[, paste0(pcampo) := ifelse(foto_mes %in% pmeses, tbl[, get(pcampo)], get(pcampo))]\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "QuraTbvTMmpf"
      },
      "id": "QuraTbvTMmpf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Corregir_interpolar <- function(pcampo, pmeses) {\n",
        "\n",
        "  tbl <- dataset[, list(\n",
        "    \"v1\" = shift(get(pcampo), 1, type = \"lag\"),\n",
        "    \"v2\" = shift(get(pcampo), 1, type = \"lead\")\n",
        "  ),\n",
        "  by = eval(PARAM$dataset_metadata$entity_id)\n",
        "  ]\n",
        "\n",
        "  tbl[, paste0(PARAM$dataset_metadata$entity_id) := NULL]\n",
        "  tbl[, promedio := rowMeans(tbl, na.rm = TRUE)]\n",
        "\n",
        "  dataset[\n",
        "    ,\n",
        "    paste0(pcampo) := ifelse(!(foto_mes %in% pmeses),\n",
        "      get(pcampo),\n",
        "      tbl$promedio\n",
        "    )\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "mUDX04VTJz3M"
      },
      "id": "mUDX04VTJz3M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AsignarNA_campomeses <- function(pcampo, pmeses) {\n",
        "\n",
        "  if( pcampo %in% colnames( dataset ) ) {\n",
        "\n",
        "    dataset[ foto_mes %in% pmeses, paste0(pcampo) := NA ]\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "Yyt2YmrbJ1zf"
      },
      "id": "Yyt2YmrbJ1zf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Corregir_atributo <- function(pcampo, pmeses, pmetodo)\n",
        "{\n",
        "  # si el campo no existe en el dataset, Afuera !\n",
        "  if( !(pcampo %in% colnames( dataset )) )\n",
        "    return( 1 )\n",
        "\n",
        "  # llamo a la funcion especializada que corresponde\n",
        "  switch( pmetodo,\n",
        "    \"MachineLearning\"     = AsignarNA_campomeses(pcampo, pmeses),\n",
        "    \"EstadisticaClasica\"  = Corregir_interpolar(pcampo, pmeses),\n",
        "    \"MICE\"                = Corregir_MICE(pcampo, pmeses),\n",
        "  )\n",
        "\n",
        "  return( 0 )\n",
        "}"
      ],
      "metadata": {
        "id": "aFBlFw7hJ4EW"
      },
      "id": "aFBlFw7hJ4EW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Corregir_Rotas <- function(dataset, pmetodo) {\n",
        "  gc(verbose= FALSE)\n",
        "  cat( \"inicio Corregir_Rotas()\\n\")\n",
        "  # acomodo los errores del dataset\n",
        "\n",
        "  Corregir_atributo(\"active_quarter\", c(202006), pmetodo) # 1\n",
        "  Corregir_atributo(\"internet\", c(202006), pmetodo) # 2\n",
        "\n",
        "  Corregir_atributo(\"mrentabilidad\", c(201905, 201910, 202006), pmetodo) # 3\n",
        "  Corregir_atributo(\"mrentabilidad_annual\", c(201905, 201910, 202006), pmetodo) # 4\n",
        "\n",
        "  Corregir_atributo(\"mcomisiones\", c(201905, 201910, 202006), pmetodo) # 5\n",
        "\n",
        "  Corregir_atributo(\"mactivos_margen\", c(201905, 201910, 202006), pmetodo) # 6\n",
        "  Corregir_atributo(\"mpasivos_margen\", c(201905, 201910, 202006), pmetodo) # 7\n",
        "\n",
        "  Corregir_atributo(\"mcuentas_saldo\", c(202006), pmetodo) # 8\n",
        "\n",
        "  Corregir_atributo(\"ctarjeta_debito_transacciones\", c(202006), pmetodo) # 9\n",
        "\n",
        "  Corregir_atributo(\"mautoservicio\", c(202006), pmetodo) # 10\n",
        "\n",
        "  Corregir_atributo(\"ctarjeta_visa_transacciones\", c(202006), pmetodo) # 11\n",
        "  Corregir_atributo(\"mtarjeta_visa_consumo\", c(202006), pmetodo) # 12\n",
        "\n",
        "  Corregir_atributo(\"ctarjeta_master_transacciones\", c(202006), pmetodo) # 13\n",
        "  Corregir_atributo(\"mtarjeta_master_consumo\", c(202006), pmetodo) # 14\n",
        "\n",
        "  Corregir_atributo(\"ctarjeta_visa_debitos_automaticos\", c(201904), pmetodo) # 15\n",
        "  Corregir_atributo(\"mttarjeta_visa_debitos_automaticos\", c(201904), pmetodo) # 16\n",
        "\n",
        "  Corregir_atributo(\"ccajeros_propios_descuentos\",\n",
        "    c(201910, 202002, 202006, 202009, 202010, 202102), pmetodo) # 17\n",
        "\n",
        "  Corregir_atributo(\"mcajeros_propios_descuentos\",\n",
        "    c(201910, 202002, 202006, 202009, 202010, 202102), pmetodo) # 18\n",
        "\n",
        "  Corregir_atributo(\"ctarjeta_visa_descuentos\",\n",
        "    c(201910, 202002, 202006, 202009, 202010, 202102), pmetodo) # 19\n",
        "\n",
        "  Corregir_atributo(\"mtarjeta_visa_descuentos\",\n",
        "    c(201910, 202002, 202006, 202009, 202010, 202102), pmetodo) # 20\n",
        "\n",
        "  Corregir_atributo(\"ctarjeta_master_descuentos\",\n",
        "    c(201910, 202002, 202006, 202009, 202010, 202102), pmetodo) # 21\n",
        "\n",
        "  Corregir_atributo(\"mtarjeta_master_descuentos\",\n",
        "    c(201910, 202002, 202006, 202009, 202010, 202102), pmetodo) # 22\n",
        "\n",
        "  Corregir_atributo(\"ccomisiones_otras\", c(201905, 201910, 202006), pmetodo) # 23\n",
        "  Corregir_atributo(\"mcomisiones_otras\", c(201905, 201910, 202006), pmetodo) # 24\n",
        "\n",
        "  Corregir_atributo(\"cextraccion_autoservicio\", c(202006), pmetodo) # 25\n",
        "  Corregir_atributo(\"mextraccion_autoservicio\", c(202006), pmetodo) # 26\n",
        "\n",
        "  Corregir_atributo(\"ccheques_depositados\", c(202006), pmetodo) # 27\n",
        "  Corregir_atributo(\"mcheques_depositados\", c(202006), pmetodo) # 28\n",
        "  Corregir_atributo(\"ccheques_emitidos\", c(202006), pmetodo) # 29\n",
        "  Corregir_atributo(\"mcheques_emitidos\", c(202006), pmetodo) # 30\n",
        "  Corregir_atributo(\"ccheques_depositados_rechazados\", c(202006), pmetodo) # 31\n",
        "  Corregir_atributo(\"mcheques_depositados_rechazados\", c(202006), pmetodo) # 32\n",
        "  Corregir_atributo(\"ccheques_emitidos_rechazados\", c(202006), pmetodo) # 33\n",
        "  Corregir_atributo(\"mcheques_emitidos_rechazados\", c(202006), pmetodo) # 34\n",
        "\n",
        "  Corregir_atributo(\"tcallcenter\", c(202006), pmetodo) # 35\n",
        "  Corregir_atributo(\"ccallcenter_transacciones\", c(202006), pmetodo) # 36\n",
        "\n",
        "  Corregir_atributo(\"thomebanking\", c(202006), pmetodo) # 37\n",
        "  Corregir_atributo(\"chomebanking_transacciones\", c(201910, 202006), pmetodo) # 38\n",
        "\n",
        "  Corregir_atributo(\"ccajas_transacciones\", c(202006), pmetodo) # 39\n",
        "  Corregir_atributo(\"ccajas_consultas\", c(202006), pmetodo) # 40\n",
        "\n",
        "  Corregir_atributo(\"ccajas_depositos\", c(202006, 202105), pmetodo) # 41\n",
        "\n",
        "  Corregir_atributo(\"ccajas_extracciones\", c(202006), pmetodo) # 41\n",
        "  Corregir_atributo(\"ccajas_otras\", c(202006), pmetodo) # 43\n",
        "\n",
        "  Corregir_atributo(\"catm_trx\", c(202006), pmetodo) # 44\n",
        "  Corregir_atributo(\"matm\", c(202006), pmetodo) # 45\n",
        "  Corregir_atributo(\"catm_trx_other\", c(202006), pmetodo) # 46\n",
        "  Corregir_atributo(\"matm_other\", c(202006), pmetodo) # 47\n",
        "\n",
        "  cat( \"fin Corregir_rotas()\\n\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "krkr3JCxJ9Px"
      },
      "id": "krkr3JCxJ9Px",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resuelvo el Catastrophe Analysis\n",
        "\n",
        "setorder( dataset, numero_de_cliente, foto_mes )\n",
        "\n",
        "PARAM$CA$metodo= \"MachineLearning\"\n",
        "\n",
        "if( PARAM$CA$metodo %in% c(\"MachineLearning\", \"EstadisticaClasica\", \"MICE\") )\n",
        "  Corregir_Rotas(dataset, PARAM$CA$metodo)"
      ],
      "metadata": {
        "id": "HaW4TeBIMxTn"
      },
      "id": "HaW4TeBIMxTn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9.7.1.3  DR  Data Drifting\n",
        "Se intenta corregir el data drifting, ajustando por algunos indices financieros"
      ],
      "metadata": {
        "id": "-4NiANYFSYHG"
      },
      "id": "-4NiANYFSYHG"
    },
    {
      "cell_type": "code",
      "source": [
        "# meses que me interesan para el ajuste de variables monetarias\n",
        "vfoto_mes <- c(\n",
        "  201901, 201902, 201903, 201904, 201905, 201906,\n",
        "  201907, 201908, 201909, 201910, 201911, 201912,\n",
        "  202001, 202002, 202003, 202004, 202005, 202006,\n",
        "  202007, 202008, 202009, 202010, 202011, 202012,\n",
        "  202101, 202102, 202103, 202104, 202105, 202106,\n",
        "  202107, 202108, 202109\n",
        ")\n"
      ],
      "metadata": {
        "id": "XXPLxqc1ShLN"
      },
      "id": "XXPLxqc1ShLN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los valores que siguen fueron calculados por alumnos\n",
        "\n",
        "# momento 1.0  31-dic-2020 a las 23:59\n",
        "vIPC <- c(\n",
        "  1.9903030878, 1.9174403544, 1.8296186587,\n",
        "  1.7728862972, 1.7212488323, 1.6776304408,\n",
        "  1.6431248196, 1.5814483345, 1.4947526791,\n",
        "  1.4484037589, 1.3913580777, 1.3404220402,\n",
        "  1.3154288912, 1.2921698342, 1.2472681797,\n",
        "  1.2300475145, 1.2118694724, 1.1881073259,\n",
        "  1.1693969743, 1.1375456949, 1.1065619600,\n",
        "  1.0681100000, 1.0370000000, 1.0000000000,\n",
        "  0.9680542110, 0.9344152616, 0.8882274350,\n",
        "  0.8532444140, 0.8251880213, 0.8003763543,\n",
        "  0.7763107219, 0.7566381305, 0.7289384687\n",
        ")\n",
        "\n",
        "vdolar_blue <- c(\n",
        "   39.045455,  38.402500,  41.639474,\n",
        "   44.274737,  46.095455,  45.063333,\n",
        "   43.983333,  54.842857,  61.059524,\n",
        "   65.545455,  66.750000,  72.368421,\n",
        "   77.477273,  78.191667,  82.434211,\n",
        "  101.087500, 126.236842, 125.857143,\n",
        "  130.782609, 133.400000, 137.954545,\n",
        "  170.619048, 160.400000, 153.052632,\n",
        "  157.900000, 149.780952, 143.615385,\n",
        "  146.250000, 153.550000, 162.000000,\n",
        "  178.478261, 180.878788, 184.357143\n",
        ")\n",
        "\n",
        "vdolar_oficial <- c(\n",
        "   38.430000,  39.428000,  42.542105,\n",
        "   44.354211,  46.088636,  44.955000,\n",
        "   43.751429,  54.650476,  58.790000,\n",
        "   61.403182,  63.012632,  63.011579,\n",
        "   62.983636,  63.580556,  65.200000,\n",
        "   67.872000,  70.047895,  72.520952,\n",
        "   75.324286,  77.488500,  79.430909,\n",
        "   83.134762,  85.484737,  88.181667,\n",
        "   91.474000,  93.997778,  96.635909,\n",
        "   98.526000,  99.613158, 100.619048,\n",
        "  101.619048, 102.569048, 103.781818\n",
        ")\n",
        "\n",
        "vUVA <- c(\n",
        "  2.001408838932958,  1.950325472789153,  1.89323032351521,\n",
        "  1.8247220405493787, 1.746027787673673,  1.6871348409529485,\n",
        "  1.6361678865622313, 1.5927529755859773, 1.5549162794128493,\n",
        "  1.4949100586391746, 1.4197729500774545, 1.3678188186372326,\n",
        "  1.3136508617223726, 1.2690535173062818, 1.2381595983200178,\n",
        "  1.211656735577568,  1.1770808941405335, 1.1570338657445522,\n",
        "  1.1388769475653255, 1.1156993751209352, 1.093638313080772,\n",
        "  1.0657171590878205, 1.0362173587708712, 1.0,\n",
        "  0.9669867858358365, 0.9323750098728378, 0.8958202912590305,\n",
        "  0.8631993702994263, 0.8253893405524657, 0.7928918905364516,\n",
        "  0.7666323845128089, 0.7428976357662823, 0.721615762047849\n",
        ")\n"
      ],
      "metadata": {
        "id": "sjjUe3waSh8D"
      },
      "id": "sjjUe3waSh8D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_indices <- as.data.table( list(\n",
        "  \"IPC\" = vIPC,\n",
        "  \"dolar_blue\" = vdolar_blue,\n",
        "  \"dolar_oficial\" = vdolar_oficial,\n",
        "  \"UVA\" = vUVA\n",
        "  )\n",
        ")\n",
        "\n",
        "tb_indices[[ 'foto_mes' ]] <- vfoto_mes\n",
        "\n",
        "tb_indices"
      ],
      "metadata": {
        "id": "RSF9i9nyWwKs"
      },
      "id": "RSF9i9nyWwKs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drift_UVA <- function(campos_monetarios) {\n",
        "  cat( \"inicio drift_UVA()\\n\")\n",
        "\n",
        "  dataset[tb_indices,\n",
        "    on = c(\"foto_mes\"),\n",
        "    (campos_monetarios) := .SD * i.UVA,\n",
        "    .SDcols = campos_monetarios\n",
        "  ]\n",
        "\n",
        "  cat( \"fin drift_UVA()\\n\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "oq2zlvpkSmAU"
      },
      "id": "oq2zlvpkSmAU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drift_dolar_oficial <- function(campos_monetarios) {\n",
        "  cat( \"inicio drift_dolar_oficial()\\n\")\n",
        "\n",
        "  dataset[tb_indices,\n",
        "    on = c(\"foto_mes\"),\n",
        "    (campos_monetarios) := .SD / i.dolar_oficial,\n",
        "    .SDcols = campos_monetarios\n",
        "  ]\n",
        "\n",
        "  cat( \"fin drift_dolar_oficial()\\n\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "h2QbqSn8Sojj"
      },
      "id": "h2QbqSn8Sojj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drift_dolar_blue <- function(campos_monetarios) {\n",
        "  cat( \"inicio drift_dolar_blue()\\n\")\n",
        "\n",
        "  dataset[tb_indices,\n",
        "    on = c(\"foto_mes\"),\n",
        "    (campos_monetarios) := .SD / i.dolar_blue,\n",
        "    .SDcols = campos_monetarios\n",
        "  ]\n",
        "\n",
        "  cat( \"fin drift_dolar_blue()\\n\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "DMTgpq9VSqqM"
      },
      "id": "DMTgpq9VSqqM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drift_deflacion <- function(campos_monetarios) {\n",
        "  cat( \"inicio drift_deflacion()\\n\")\n",
        "\n",
        "  dataset[tb_indices,\n",
        "    on = c(\"foto_mes\"),\n",
        "    (campos_monetarios) := .SD * i.IPC,\n",
        "    .SDcols = campos_monetarios\n",
        "  ]\n",
        "\n",
        "  cat( \"fin drift_deflacion()\\n\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "7n171_BoStAj"
      },
      "id": "7n171_BoStAj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drift_rank_simple <- function(campos_drift) {\n",
        "\n",
        "  cat( \"inicio drift_rank_simple()\\n\")\n",
        "  for (campo in campos_drift)\n",
        "  {\n",
        "    cat(campo, \" \")\n",
        "    dataset[, paste0(campo, \"_rank\") :=\n",
        "      (frank(get(campo), ties.method = \"random\") - 1) / (.N - 1), by = list(foto_mes)]\n",
        "    dataset[, (campo) := NULL]\n",
        "  }\n",
        "  cat( \"fin drift_rank_simple()\\n\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "Z94UizNySv0m"
      },
      "id": "Z94UizNySv0m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# El cero se transforma en cero\n",
        "# los positivos se rankean por su lado\n",
        "# los negativos se rankean por su lado\n",
        "\n",
        "drift_rank_cero_fijo <- function(campos_drift) {\n",
        "\n",
        "  cat( \"inicio drift_rank_cero_fijo()\\n\")\n",
        "  for (campo in campos_drift)\n",
        "  {\n",
        "    cat(campo, \" \")\n",
        "    dataset[get(campo) == 0, paste0(campo, \"_rank\") := 0]\n",
        "    dataset[get(campo) > 0, paste0(campo, \"_rank\") :=\n",
        "      frank(get(campo), ties.method = \"random\") / .N, by = list(foto_mes)]\n",
        "\n",
        "    dataset[get(campo) < 0, paste0(campo, \"_rank\") :=\n",
        "      -frank(-get(campo), ties.method = \"random\") / .N, by = list(foto_mes)]\n",
        "    dataset[, (campo) := NULL]\n",
        "  }\n",
        "  cat(\"\\n\")\n",
        "  cat( \"fin drift_rank_cero_fijo()\\n\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "GnbUIXeWSyQm"
      },
      "id": "GnbUIXeWSyQm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drift_estandarizar <- function(campos_drift) {\n",
        "\n",
        "  cat( \"inicio drift_estandarizar()\\n\")\n",
        "  for (campo in campos_drift)\n",
        "  {\n",
        "    cat(campo, \" \")\n",
        "    dataset[, paste0(campo, \"_normal\") :=\n",
        "      (get(campo) -mean(campo, na.rm=TRUE)) / sd(get(campo), na.rm=TRUE),\n",
        "      by = list(foto_mes)]\n",
        "\n",
        "    dataset[, (campo) := NULL]\n",
        "  }\n",
        "  cat( \"fin drift_estandarizar()\\n\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "dhlyk-WxS040"
      },
      "id": "dhlyk-WxS040",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# por como armé los nombres de campos,\n",
        "#  estos son los campos que expresan variables monetarias\n",
        "campos_monetarios <- colnames(dataset)\n",
        "campos_monetarios <- campos_monetarios[campos_monetarios %like%\n",
        "  \"^(m|Visa_m|Master_m|vm_m)\"]\n",
        "\n",
        "campos_monetarios"
      ],
      "metadata": {
        "id": "tlJjlN6PVanz"
      },
      "id": "tlJjlN6PVanz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecuto el Data Drifting\n",
        "setorder( dataset, numero_de_cliente, foto_mes )\n",
        "\n",
        "\n",
        "PARAM$DR$metodo <- \"deflacion\"\n",
        "\n",
        "switch(PARAM$DR$metodo,\n",
        "  \"ninguno\"        = cat(\"No hay correccion del data drifting\"),\n",
        "  \"rank_simple\"    = drift_rank_simple(campos_monetarios),\n",
        "  \"rank_cero_fijo\" = drift_rank_cero_fijo(campos_monetarios),\n",
        "  \"deflacion\"      = drift_deflacion(campos_monetarios),\n",
        "  \"dolar_blue\"     = drift_dolarblue(campos_monetarios),\n",
        "  \"dolar_oficial\"  = drift_dolaroficial(campos_monetarios),\n",
        "  \"UVA\"            = drift_UVA(campos_monetarios),\n",
        "  \"estandarizar\"   = drift_estandarizar(campos_monetarios)\n",
        ")\n"
      ],
      "metadata": {
        "id": "G_8BH82XS3uV"
      },
      "id": "G_8BH82XS3uV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colnames(dataset)"
      ],
      "metadata": {
        "id": "-efBawbTWPKc"
      },
      "id": "-efBawbTWPKc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9.7.1.3  FE_intra_manual Feature Engineering intra-mes\n",
        "\n",
        "Agrego campos nuevos dentro del mismo mes, SIN considerar la historia."
      ],
      "metadata": {
        "id": "7sppIDYeSn5X"
      },
      "id": "7sppIDYeSn5X"
    },
    {
      "cell_type": "code",
      "source": [
        "if( !require(\"lubridate\")) install.packages(\"lubridate\", repos = \"http://cran.us.r-project.org\")\n",
        "require(\"lubridate\")"
      ],
      "metadata": {
        "id": "g_UYTueTagt4"
      },
      "id": "g_UYTueTagt4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# esta funcion atributos presentes existe debido a que las modalidades poseen datasets con distinta cantidad de campos\n",
        "atributos_presentes <- function( patributos )\n",
        "{\n",
        "  atributos <- unique( patributos )\n",
        "  comun <- intersect( atributos, colnames(dataset) )\n",
        "\n",
        "  return(  length( atributos ) == length( comun ) )\n",
        "}"
      ],
      "metadata": {
        "id": "qrqf3j3_St3p"
      },
      "id": "qrqf3j3_St3p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta es la parte que los alumnos deben desplegar todo su ingenio\n",
        "# Agregar aqui sus PROPIAS VARIABLES manuales\n",
        "\n",
        "AgregarVariables_IntraMes <- function(dataset) {\n",
        "  cat( \"inicio AgregarVariables_IntraMes()\\n\")\n",
        "  gc(verbose= FALSE)\n",
        "  # INICIO de la seccion donde se deben hacer cambios con variables nuevas\n",
        "\n",
        "  # el mes 1,2, ..12\n",
        "  if( atributos_presentes( c(\"foto_mes\") ))\n",
        "    dataset[, kmes := foto_mes %% 100]\n",
        "\n",
        "  # creo un ctr_quarter que tenga en cuenta cuando\n",
        "  # los clientes hace 3 menos meses que estan\n",
        "  # ya que seria injusto considerar las transacciones medidas en menor tiempo\n",
        "  if( atributos_presentes( c(\"ctrx_quarter\") ))\n",
        "    dataset[, ctrx_quarter_normalizado := as.numeric(ctrx_quarter) ]\n",
        "\n",
        "  if( atributos_presentes( c(\"ctrx_quarter\", \"cliente_antiguedad\") ))\n",
        "    dataset[cliente_antiguedad == 1, ctrx_quarter_normalizado := ctrx_quarter * 5]\n",
        "\n",
        "  if( atributos_presentes( c(\"ctrx_quarter\", \"cliente_antiguedad\") ))\n",
        "    dataset[cliente_antiguedad == 2, ctrx_quarter_normalizado := ctrx_quarter * 2]\n",
        "\n",
        "  if( atributos_presentes( c(\"ctrx_quarter\", \"cliente_antiguedad\") ))\n",
        "    dataset[\n",
        "      cliente_antiguedad == 3,\n",
        "      ctrx_quarter_normalizado := ctrx_quarter * 1.2\n",
        "    ]\n",
        "\n",
        "   if(atributos_presentes(c(\"foto_mes\")))\n",
        "    dataset[,foto_mes_formato_fecha := as.Date(paste(substr(dataset$foto_mes,1,4),substr(dataset$foto_mes,5,6),\"01\",sep='-'))]\n",
        "\n",
        "  #dataset$foto_mes_formato_fecha <<- as.Date(paste(substr(dataset$foto_mes,1,4),substr(dataset$foto_mes,5,6),\"01\",sep='-'))\n",
        "\n",
        "  if(atributos_presentes(c(\"cantidad_total_transacciones\"))){\n",
        "   auxiliarmenos1 <- dataset[,list(numero_de_cliente,foto_mes_formato_fecha, cantidad_total_transacciones)]\n",
        "   auxiliarmenos2 <- dataset[,list(numero_de_cliente,foto_mes_formato_fecha,cantidad_total_transacciones)]\n",
        "   # auxiliarmenos1$foto_mes_formato_fecha <- as.Date(auxiliarmenos1$foto_mes_formato_fecha)\n",
        "   # auxiliarmenos2$foto_mes_formato_fecha <- as.Date(auxiliarmenos2$foto_mes_formato_fecha)\n",
        "   auxiliarmenos1$foto_mes_formato_fecha <- auxiliarmenos1$foto_mes_formato_fecha  %m-%  months(1)\n",
        "   auxiliarmenos2$foto_mes_formato_fecha <- auxiliarmenos2$foto_mes_formato_fecha %m-% months(2)\n",
        "   auxiliarmenos1$codigo <- paste(auxiliarmenos1$numero_de_cliente,auxiliarmenos1$foto_mes_formato_fecha,sep='-')\n",
        "   auxiliarmenos2$codigo <- paste(auxiliarmenos2$numero_de_cliente,auxiliarmenos2$foto_mes_formato_fecha,sep='-')\n",
        "\n",
        "   dataset[, codigo := paste(numero_de_cliente, foto_mes_formato_fecha, sep='-') ]\n",
        "\n",
        "   dataset[ auxiliarmenos1,\n",
        "            on = \"codigo\",\n",
        "            transaccionesmenos1 := i.cantidad_total_transacciones ]\n",
        "\n",
        "   dataset[ auxiliarmenos2,\n",
        "            on = \"codigo\",\n",
        "            transaccionesmenos2 := i.cantidad_total_transacciones ]\n",
        "\n",
        "   dataset[, cantidad_total_transacciones_quarter := rowSums(cbind(cantidad_total_transacciones +\n",
        "    transaccionesmenos1 + transaccionesmenos2),na.rm=T) ]\n",
        "\n",
        "   dataset[, codigo := NULL ]\n",
        "   dataset[, transaccionesmenos1 := NULL ]\n",
        "   dataset[, transaccionesmenos2 := NULL ]\n",
        "   dataset[, foto_mes_formato_fecha := NULL ]\n",
        "   rm(auxiliarmenos1)\n",
        "   rm(auxiliarmenos2)\n",
        "  }\n",
        "\n",
        "  if( atributos_presentes( c(\"cantidad_total_transacciones_quarter\") ))\n",
        "    dataset[, cantidad_total_transacciones_quarter_normalizado := cantidad_total_transacciones_quarter]\n",
        "\n",
        "  if( atributos_presentes( c(\"cantidad_total_transacciones_quarter\", \"cliente_antiguedad\") ))\n",
        "    dataset[cliente_antiguedad == 1, cantidad_total_transacciones_quarter_normalizado := cantidad_total_transacciones_quarter * 5]\n",
        "\n",
        "  if( atributos_presentes( c(\"cantidad_total_transacciones_quarter\", \"cliente_antiguedad\") ))\n",
        "    dataset[cliente_antiguedad == 2, cantidad_total_transacciones_quarter_normalizado := cantidad_total_transacciones_quarter * 2]\n",
        "\n",
        "  if( atributos_presentes( c(\"cantidad_total_transacciones_quarter\", \"cliente_antiguedad\") ))\n",
        "    dataset[cliente_antiguedad == 3, cantidad_total_transacciones_quarter_normalizado := cantidad_total_transacciones_quarter * 1.2]\n",
        "\n",
        "  # variable extraida de una tesis de maestria de Irlanda\n",
        "  if( atributos_presentes( c(\"mpayroll\", \"cliente_edad\") ))\n",
        "    dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n",
        "\n",
        "  # se crean los nuevos campos para MasterCard  y Visa,\n",
        "  #  teniendo en cuenta los NA's\n",
        "  # varias formas de combinar Visa_status y Master_status\n",
        "  if( atributos_presentes( c(\"Master_status\", \"Visa_status\") ))\n",
        "  {\n",
        "    dataset[, vm_status01 := pmax(Master_status, Visa_status, na.rm = TRUE)]\n",
        "    dataset[, vm_status02 := Master_status + Visa_status]\n",
        "\n",
        "    dataset[, vm_status03 := pmax(\n",
        "      ifelse(is.na(Master_status), 10, Master_status),\n",
        "      ifelse(is.na(Visa_status), 10, Visa_status)\n",
        "    )]\n",
        "\n",
        "    dataset[, vm_status04 := ifelse(is.na(Master_status), 10, Master_status)\n",
        "      + ifelse(is.na(Visa_status), 10, Visa_status)]\n",
        "\n",
        "    dataset[, vm_status05 := ifelse(is.na(Master_status), 10, Master_status)\n",
        "      + 100 * ifelse(is.na(Visa_status), 10, Visa_status)]\n",
        "\n",
        "    dataset[, vm_status06 := ifelse(is.na(Visa_status),\n",
        "      ifelse(is.na(Master_status), 10, Master_status),\n",
        "      Visa_status\n",
        "    )]\n",
        "\n",
        "    dataset[, mv_status07 := ifelse(is.na(Master_status),\n",
        "      ifelse(is.na(Visa_status), 10, Visa_status),\n",
        "      Master_status\n",
        "    )]\n",
        "  }\n",
        "\n",
        "\n",
        "  # combino MasterCard y Visa\n",
        "  if( atributos_presentes( c(\"Master_mfinanciacion_limite\", \"Visa_mfinanciacion_limite\") ))\n",
        "    dataset[, vm_mfinanciacion_limite := rowSums(cbind(Master_mfinanciacion_limite, Visa_mfinanciacion_limite), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_Fvencimiento\", \"Visa_Fvencimiento\") ))\n",
        "    dataset[, vm_Fvencimiento := pmin(Master_Fvencimiento, Visa_Fvencimiento, na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_Finiciomora\", \"Visa_Finiciomora\") ))\n",
        "    dataset[, vm_Finiciomora := pmin(Master_Finiciomora, Visa_Finiciomora, na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_msaldototal\", \"Visa_msaldototal\") ))\n",
        "    dataset[, vm_msaldototal := rowSums(cbind(Master_msaldototal, Visa_msaldototal), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_msaldopesos\", \"Visa_msaldopesos\") ))\n",
        "    dataset[, vm_msaldopesos := rowSums(cbind(Master_msaldopesos, Visa_msaldopesos), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_msaldodolares\", \"Visa_msaldodolares\") ))\n",
        "    dataset[, vm_msaldodolares := rowSums(cbind(Master_msaldodolares, Visa_msaldodolares), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_mconsumospesos\", \"Visa_mconsumospesos\") ))\n",
        "    dataset[, vm_mconsumospesos := rowSums(cbind(Master_mconsumospesos, Visa_mconsumospesos), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_mconsumosdolares\", \"Visa_mconsumosdolares\") ))\n",
        "    dataset[, vm_mconsumosdolares := rowSums(cbind(Master_mconsumosdolares, Visa_mconsumosdolares), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_mlimitecompra\", \"Visa_mlimitecompra\") ))\n",
        "    dataset[, vm_mlimitecompra := rowSums(cbind(Master_mlimitecompra, Visa_mlimitecompra), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_madelantopesos\", \"Visa_madelantopesos\") ))\n",
        "    dataset[, vm_madelantopesos := rowSums(cbind(Master_madelantopesos, Visa_madelantopesos), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_madelantodolares\", \"Visa_madelantodolares\") ))\n",
        "    dataset[, vm_madelantodolares := rowSums(cbind(Master_madelantodolares, Visa_madelantodolares), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_fultimo_cierre\", \"Visa_fultimo_cierre\") ))\n",
        "    dataset[, vm_fultimo_cierre := pmax(Master_fultimo_cierre, Visa_fultimo_cierre, na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_mpagado\", \"Visa_mpagado\") ))\n",
        "    dataset[, vm_mpagado := rowSums(cbind(Master_mpagado, Visa_mpagado), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_mpagospesos\", \"Visa_mpagospesos\") ))\n",
        "    dataset[, vm_mpagospesos := rowSums(cbind(Master_mpagospesos, Visa_mpagospesos), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_mpagosdolares\", \"Visa_mpagosdolares\") ))\n",
        "    dataset[, vm_mpagosdolares := rowSums(cbind(Master_mpagosdolares, Visa_mpagosdolares), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_fechaalta\", \"Visa_fechaalta\") ))\n",
        "    dataset[, vm_fechaalta := pmax(Master_fechaalta, Visa_fechaalta, na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_mconsumototal\", \"Visa_mconsumototal\") ))\n",
        "    dataset[, vm_mconsumototal := rowSums(cbind(Master_mconsumototal, Visa_mconsumototal), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_cconsumos\", \"Visa_cconsumos\") ))\n",
        "    dataset[, vm_cconsumos := rowSums(cbind(Master_cconsumos, Visa_cconsumos), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_cadelantosefectivo\", \"Visa_cadelantosefectivo\") ))\n",
        "    dataset[, vm_cadelantosefectivo := rowSums(cbind(Master_cadelantosefectivo, Visa_cadelantosefectivo), na.rm = TRUE)]\n",
        "\n",
        "  if( atributos_presentes( c(\"Master_mpagominimo\", \"Visa_mpagominimo\") ))\n",
        "    dataset[, vm_mpagominimo := rowSums(cbind(Master_mpagominimo, Visa_mpagominimo), na.rm = TRUE)]\n",
        "\n",
        "  # a partir de aqui juego con la suma de Mastercard y Visa\n",
        "  if( atributos_presentes( c(\"Master_mlimitecompra\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_Master_mlimitecompra := Master_mlimitecompra / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"Visa_mlimitecompra\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_Visa_mlimitecompra := Visa_mlimitecompra / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_msaldototal\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_msaldototal := vm_msaldototal / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_msaldopesos\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_msaldopesos := vm_msaldopesos / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_msaldopesos\", \"vm_msaldototal\") ))\n",
        "    dataset[, vmr_msaldopesos2 := vm_msaldopesos / vm_msaldototal]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_msaldodolares\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_msaldodolares := vm_msaldodolares / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_msaldodolares\", \"vm_msaldototal\") ))\n",
        "    dataset[, vmr_msaldodolares2 := vm_msaldodolares / vm_msaldototal]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_mconsumospesos\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_mconsumospesos := vm_mconsumospesos / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_mconsumosdolares\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_mconsumosdolares := vm_mconsumosdolares / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_madelantopesos\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_madelantopesos := vm_madelantopesos / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_madelantodolares\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_madelantodolares := vm_madelantodolares / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_mpagado\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_mpagado := vm_mpagado / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_mpagospesos\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_mpagospesos := vm_mpagospesos / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_mpagosdolares\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_mpagosdolares := vm_mpagosdolares / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_mconsumototal\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_mconsumototal := vm_mconsumototal / vm_mlimitecompra]\n",
        "\n",
        "  if( atributos_presentes( c(\"vm_mpagominimo\", \"vm_mlimitecompra\") ))\n",
        "    dataset[, vmr_mpagominimo := vm_mpagominimo / vm_mlimitecompra]\n",
        "\n",
        "  # Aqui debe usted agregar sus propias nuevas variables\n",
        "\n",
        "  # valvula de seguridad para evitar valores infinitos\n",
        "  # paso los infinitos a NULOS\n",
        "  infinitos <- lapply(\n",
        "    names(dataset),\n",
        "    function(.name) dataset[, sum(is.infinite(get(.name)))]\n",
        "  )\n",
        "\n",
        "  infinitos_qty <- sum(unlist(infinitos))\n",
        "  if (infinitos_qty > 0) {\n",
        "    cat(\n",
        "      \"ATENCION, hay\", infinitos_qty,\n",
        "      \"valores infinitos en tu dataset. Seran pasados a NA\\n\"\n",
        "    )\n",
        "    dataset[mapply(is.infinite, dataset)] <<- NA\n",
        "  }\n",
        "\n",
        "\n",
        "  # valvula de seguridad para evitar valores NaN  que es 0/0\n",
        "  # paso los NaN a 0 , decision polemica si las hay\n",
        "  # se invita a asignar un valor razonable segun la semantica del campo creado\n",
        "  nans <- lapply(\n",
        "    names(dataset),\n",
        "    function(.name) dataset[, sum(is.nan(get(.name)))]\n",
        "  )\n",
        "\n",
        "  nans_qty <- sum(unlist(nans))\n",
        "  if (nans_qty > 0) {\n",
        "    cat(\n",
        "      \"ATENCION, hay\", nans_qty,\n",
        "      \"valores NaN 0/0 en tu dataset. Seran pasados arbitrariamente a 0\\n\"\n",
        "    )\n",
        "\n",
        "    cat(\"Si no te gusta la decision, modifica a gusto el programa!\\n\\n\")\n",
        "    dataset[mapply(is.nan, dataset)] <<- 0\n",
        "  }\n",
        "\n",
        "  cat( \"fin AgregarVariables_IntraMes()\\n\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "zjV20uzYaXVK"
      },
      "id": "zjV20uzYaXVK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agrego las variables intra mes\n",
        "\n",
        "AgregarVariables_IntraMes(dataset)"
      ],
      "metadata": {
        "id": "qGxBfj3qa5LS"
      },
      "id": "qGxBfj3qa5LS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizo las columas del dataset a esta etapa\n",
        "ncol(dataset)\n",
        "colnames(dataset)"
      ],
      "metadata": {
        "id": "iC4viwOdY5Kp"
      },
      "id": "iC4viwOdY5Kp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9.7.1.4  FEhist Feature Engineering historico\n",
        "\n",
        "El Fature Engineering Histórico es la etapa que más aporta a la ganancia final, ya que enriquece cada registro del dataset con su historia."
      ],
      "metadata": {
        "id": "0nrwNrVEmdmF"
      },
      "id": "0nrwNrVEmdmF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sew6lvjmdmV"
      },
      "source": [
        "Para cada campo del dataset original (*)\n",
        "se crean lo siguientes campos de a partir de la historia\n",
        "* lag1  lags de orden 1\n",
        "* delta1  =  valor actual - lag1\n",
        "* lag2  lags de orden 2\n",
        "* delta2  = valor actual - lag2\n",
        "\n",
        "\n",
        "(*) Excepto para los campos  <numero_de_cliente,  foto_mes,  clase_ternaria>"
      ],
      "id": "5sew6lvjmdmV"
    },
    {
      "cell_type": "code",
      "source": [
        "if( !require(\"Rcpp\")) install.packages(\"Rcpp\", repos = \"http://cran.us.r-project.org\")\n",
        "require(\"Rcpp\")"
      ],
      "metadata": {
        "id": "7ojmYMB4q9WK"
      },
      "id": "7ojmYMB4q9WK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# se calculan para los 6 meses previos el minimo, maximo y\n",
        "#  tendencia calculada con cuadrados minimos\n",
        "# la formula de calculo de la tendencia puede verse en\n",
        "#  https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.04%3A_The_Least_Squares_Regression_Line\n",
        "# para la maxíma velocidad esta funcion esta escrita en lenguaje C,\n",
        "# y no en la porqueria de R o Python\n",
        "\n",
        "cppFunction(\"NumericVector fhistC(NumericVector pcolumna, IntegerVector pdesde )\n",
        "{\n",
        "  /* Aqui se cargan los valores para la regresion */\n",
        "  double  x[100] ;\n",
        "  double  y[100] ;\n",
        "\n",
        "  int n = pcolumna.size();\n",
        "  NumericVector out( 5*n );\n",
        "\n",
        "  for(int i = 0; i < n; i++)\n",
        "  {\n",
        "    //lag\n",
        "    if( pdesde[i]-1 < i )  out[ i + 4*n ]  =  pcolumna[i-1] ;\n",
        "    else                   out[ i + 4*n ]  =  NA_REAL ;\n",
        "\n",
        "\n",
        "    int  libre    = 0 ;\n",
        "    int  xvalor   = 1 ;\n",
        "\n",
        "    for( int j= pdesde[i]-1;  j<=i; j++ )\n",
        "    {\n",
        "       double a = pcolumna[j] ;\n",
        "\n",
        "       if( !R_IsNA( a ) )\n",
        "       {\n",
        "          y[ libre ]= a ;\n",
        "          x[ libre ]= xvalor ;\n",
        "          libre++ ;\n",
        "       }\n",
        "\n",
        "       xvalor++ ;\n",
        "    }\n",
        "\n",
        "    /* Si hay al menos dos valores */\n",
        "    if( libre > 1 )\n",
        "    {\n",
        "      double  xsum  = x[0] ;\n",
        "      double  ysum  = y[0] ;\n",
        "      double  xysum = xsum * ysum ;\n",
        "      double  xxsum = xsum * xsum ;\n",
        "      double  vmin  = y[0] ;\n",
        "      double  vmax  = y[0] ;\n",
        "\n",
        "      for( int h=1; h<libre; h++)\n",
        "      {\n",
        "        xsum  += x[h] ;\n",
        "        ysum  += y[h] ;\n",
        "        xysum += x[h]*y[h] ;\n",
        "        xxsum += x[h]*x[h] ;\n",
        "\n",
        "        if( y[h] < vmin )  vmin = y[h] ;\n",
        "        if( y[h] > vmax )  vmax = y[h] ;\n",
        "      }\n",
        "\n",
        "      out[ i ]  =  (libre*xysum - xsum*ysum)/(libre*xxsum -xsum*xsum) ;\n",
        "      out[ i + n ]    =  vmin ;\n",
        "      out[ i + 2*n ]  =  vmax ;\n",
        "      out[ i + 3*n ]  =  ysum / libre ;\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "      out[ i       ]  =  NA_REAL ;\n",
        "      out[ i + n   ]  =  NA_REAL ;\n",
        "      out[ i + 2*n ]  =  NA_REAL ;\n",
        "      out[ i + 3*n ]  =  NA_REAL ;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return  out;\n",
        "}\")\n"
      ],
      "metadata": {
        "id": "nNSBhC7_rQ8B"
      },
      "id": "nNSBhC7_rQ8B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calcula la tendencia de las variables cols de los ultimos 6 meses\n",
        "# la tendencia es la pendiente de la recta que ajusta por cuadrados minimos\n",
        "# La funcionalidad de ratioavg es autoria de  Daiana Sparta,  UAustral  2021\n",
        "\n",
        "TendenciaYmuchomas <- function(\n",
        "    dataset, cols, ventana = 6, tendencia = TRUE,\n",
        "    minimo = TRUE, maximo = TRUE, promedio = TRUE,\n",
        "    ratioavg = FALSE, ratiomax = FALSE) {\n",
        "  gc(verbose= FALSE)\n",
        "  # Esta es la cantidad de meses que utilizo para la historia\n",
        "  ventana_regresion <- ventana\n",
        "\n",
        "  last <- nrow(dataset)\n",
        "\n",
        "  # creo el vector_desde que indica cada ventana\n",
        "  # de esta forma se acelera el procesamiento ya que lo hago una sola vez\n",
        "  vector_ids <- dataset[ , numero_de_cliente ]\n",
        "\n",
        "  vector_desde <- seq(\n",
        "    -ventana_regresion + 2,\n",
        "    nrow(dataset) - ventana_regresion + 1\n",
        "  )\n",
        "\n",
        "  vector_desde[1:ventana_regresion] <- 1\n",
        "\n",
        "  for (i in 2:last) {\n",
        "    if (vector_ids[i - 1] != vector_ids[i]) {\n",
        "      vector_desde[i] <- i\n",
        "    }\n",
        "  }\n",
        "  for (i in 2:last) {\n",
        "    if (vector_desde[i] < vector_desde[i - 1]) {\n",
        "      vector_desde[i] <- vector_desde[i - 1]\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (campo in cols) {\n",
        "    nueva_col <- fhistC(dataset[, get(campo)], vector_desde)\n",
        "\n",
        "    if (tendencia) {\n",
        "      dataset[, paste0(campo, \"_tend\", ventana) :=\n",
        "        nueva_col[(0 * last + 1):(1 * last)]]\n",
        "    }\n",
        "\n",
        "    if (minimo) {\n",
        "      dataset[, paste0(campo, \"_min\", ventana) :=\n",
        "        nueva_col[(1 * last + 1):(2 * last)]]\n",
        "    }\n",
        "\n",
        "    if (maximo) {\n",
        "      dataset[, paste0(campo, \"_max\", ventana) :=\n",
        "        nueva_col[(2 * last + 1):(3 * last)]]\n",
        "    }\n",
        "\n",
        "    if (promedio) {\n",
        "      dataset[, paste0(campo, \"_avg\", ventana) :=\n",
        "        nueva_col[(3 * last + 1):(4 * last)]]\n",
        "    }\n",
        "\n",
        "    if (ratioavg) {\n",
        "      dataset[, paste0(campo, \"_ratioavg\", ventana) :=\n",
        "        get(campo) / nueva_col[(3 * last + 1):(4 * last)]]\n",
        "    }\n",
        "\n",
        "    if (ratiomax) {\n",
        "      dataset[, paste0(campo, \"_ratiomax\", ventana) :=\n",
        "        get(campo) / nueva_col[(2 * last + 1):(3 * last)]]\n",
        "    }\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "CLglpZ1zrRvj"
      },
      "id": "CLglpZ1zrRvj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8WZFUvkmdmV"
      },
      "outputs": [],
      "source": [
        "# Feature Engineering Historico\n",
        "\n",
        "setorder(dataset, numero_de_cliente, foto_mes)\n",
        "\n",
        "# todo es lagueable, menos la primary key y la clase\n",
        "cols_lagueables <- copy( setdiff(\n",
        "    colnames(dataset),\n",
        "    c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
        ") )\n",
        "\n",
        "# https://rdrr.io/cran/data.table/man/shift.html\n",
        "\n",
        "# lags de orden 1\n",
        "dataset[,\n",
        "    paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
        "    by = numero_de_cliente,\n",
        "    .SDcols = cols_lagueables\n",
        "]\n",
        "\n",
        "# lags de orden 2\n",
        "dataset[,\n",
        "    paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
        "    by = numero_de_cliente,\n",
        "    .SDcols = cols_lagueables\n",
        "]\n",
        "\n",
        "# agrego los delta lags\n",
        "for (vcol in cols_lagueables)\n",
        "{\n",
        "    dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
        "    dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
        "}\n"
      ],
      "id": "Q8WZFUvkmdmV"
    },
    {
      "cell_type": "code",
      "source": [
        "# parametros de Feature Engineering Historico de Tendencias\n",
        "PARAM$FE_hist$Tendencias$run <- TRUE\n",
        "PARAM$FE_hist$Tendencias$ventana <- 6\n",
        "PARAM$FE_hist$Tendencias$tendencia <- TRUE\n",
        "PARAM$FE_hist$Tendencias$minimo <- FALSE\n",
        "PARAM$FE_hist$Tendencias$maximo <- FALSE\n",
        "PARAM$FE_hist$Tendencias$promedio <- FALSE\n",
        "PARAM$FE_hist$Tendencias$ratioavg <- FALSE\n",
        "PARAM$FE_hist$Tendencias$ratiomax <- FALSE\n"
      ],
      "metadata": {
        "id": "SDRCLwCMsC70"
      },
      "id": "SDRCLwCMsC70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_lagueables <- intersect(cols_lagueables, colnames(dataset))\n",
        "setorder(dataset, numero_de_cliente, foto_mes)\n",
        "\n",
        "if( PARAM$FE_hist$Tendencias$run) {\n",
        "    TendenciaYmuchomas(dataset,\n",
        "    cols = cols_lagueables,\n",
        "    ventana = PARAM$FE_hist$Tendencias$ventana, # 6 meses de historia\n",
        "    tendencia = PARAM$FE_hist$Tendencias$tendencia,\n",
        "    minimo = PARAM$FE_hist$Tendencias$minimo,\n",
        "    maximo = PARAM$FE_hist$Tendencias$maximo,\n",
        "    promedio = PARAM$FE_hist$Tendencias$promedio,\n",
        "    ratioavg = PARAM$FE_hist$Tendencias$ratioavg,\n",
        "    ratiomax = PARAM$FE_hist$Tendencias$ratiomax\n",
        "  )\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "MunPUc8ur0lY"
      },
      "id": "MunPUc8ur0lY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCbELQZ6mdmW"
      },
      "source": [
        "Verificacion de los campos recien creados"
      ],
      "id": "MCbELQZ6mdmW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBcqLABAmdmW"
      },
      "outputs": [],
      "source": [
        "ncol(dataset)\n",
        "colnames(dataset)"
      ],
      "id": "RBcqLABAmdmW"
    },
    {
      "cell_type": "markdown",
      "id": "9682b4ca-3ab3-4bbc-a36a-b185361e6b6b",
      "metadata": {
        "id": "9682b4ca-3ab3-4bbc-a36a-b185361e6b6b"
      },
      "source": [
        "#### 9.7.1.5  FE_rf Feature Engineering de nuevas variables a partir de hojas de Random Forest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")"
      ],
      "metadata": {
        "id": "Vd09ZaybfUeK"
      },
      "id": "Vd09ZaybfUeK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AgregaVarRandomForest <- function() {\n",
        "\n",
        "  cat( \"inicio AgregaVarRandomForest()\\n\")\n",
        "  gc(verbose= FALSE)\n",
        "  dataset[, clase01 := 0L ]\n",
        "  dataset[ clase_ternaria %in% PARAM$FE_rf$train$clase01_valor1,\n",
        "      clase01 := 1L ]\n",
        "\n",
        "  campos_buenos <- setdiff(\n",
        "    colnames(dataset),\n",
        "    c( \"clase_ternaria\", \"clase01\")\n",
        "  )\n",
        "\n",
        "  dataset[, entrenamiento :=\n",
        "    as.integer( foto_mes %in% PARAM$FE_rf$train$training )]\n",
        "\n",
        "  dtrain <- lgb.Dataset(\n",
        "    data = data.matrix(dataset[entrenamiento == TRUE, campos_buenos, with = FALSE]),\n",
        "    label = dataset[entrenamiento == TRUE, clase01],\n",
        "    free_raw_data = FALSE\n",
        "  )\n",
        "\n",
        "  modelo <- lgb.train(\n",
        "     data = dtrain,\n",
        "     param = PARAM$FE_rf$lgb_param,\n",
        "     verbose = -100\n",
        "  )\n",
        "\n",
        "  cat( \"Fin construccion RandomForest\\n\" )\n",
        "  # grabo el modelo, achivo .model\n",
        "  lgb.save(modelo, file=\"modelo.model\" )\n",
        "\n",
        "  qarbolitos <- copy(PARAM$FE_rf$lgb_param$num_iterations)\n",
        "\n",
        "  periodos <- dataset[ , unique( foto_mes ) ]\n",
        "\n",
        "  for( periodo in  periodos )\n",
        "  {\n",
        "    cat( \"periodo = \", periodo, \"\\n\" )\n",
        "    datamatrix <- data.matrix(dataset[ foto_mes== periodo, campos_buenos, with = FALSE])\n",
        "\n",
        "    cat( \"Inicio prediccion\\n\" )\n",
        "    prediccion <- predict(\n",
        "        modelo,\n",
        "        datamatrix,\n",
        "        type = \"leaf\"\n",
        "    )\n",
        "    cat( \"Fin prediccion\\n\" )\n",
        "\n",
        "    for( arbolito in 1:qarbolitos )\n",
        "    {\n",
        "       cat( arbolito, \" \" )\n",
        "       hojas_arbol <- unique(prediccion[ , arbolito])\n",
        "\n",
        "       for (pos in 1:length(hojas_arbol)) {\n",
        "         # el numero de nodo de la hoja, estan salteados\n",
        "         nodo_id <- hojas_arbol[pos]\n",
        "         dataset[ foto_mes== periodo, paste0(\n",
        "            \"rf_\", sprintf(\"%03d\", arbolito),\n",
        "             \"_\", sprintf(\"%03d\", nodo_id)\n",
        "          ) :=  as.integer( nodo_id == prediccion[ , arbolito]) ]\n",
        "\n",
        "       }\n",
        "\n",
        "       rm( hojas_arbol )\n",
        "    }\n",
        "    cat( \"\\n\" )\n",
        "\n",
        "    rm( prediccion )\n",
        "    rm( datamatrix )\n",
        "    gc(verbose= FALSE)\n",
        "  }\n",
        "\n",
        "  gc(verbose= FALSE)\n",
        "\n",
        "  # borro clase01 , no debe ensuciar el dataset\n",
        "  dataset[ , clase01 := NULL ]\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "JrsaXcQqcefM"
      },
      "id": "JrsaXcQqcefM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros de Feature Engineering  a partir de hojas de Random Forest\n",
        "\n",
        "# Estos CUATRO parametros son los que se deben modificar\n",
        "PARAM$FE_rf$arbolitos= 20\n",
        "PARAM$FE_rf$hojas_por_arbol= 16\n",
        "PARAM$FE_rf$datos_por_hoja= 100\n",
        "PARAM$FE_rf$mtry_ratio= 0.2\n",
        "\n",
        "# Estos son quasi fijos\n",
        "PARAM$FE_rf$train$clase01_valor1 <- c( \"BAJA+2\", \"BAJA+1\")\n",
        "PARAM$FE_rf$train$training <- c( 202101, 202102, 202103)\n",
        "\n",
        "# Estos TAMBIEN son quasi fijos\n",
        "PARAM$FE_rf$lgb_param <-list(\n",
        "    # parametros que se pueden cambiar\n",
        "    num_iterations = PARAM$FE_rf$arbolitos,\n",
        "    num_leaves  = PARAM$FE_rf$hojas_por_arbol,\n",
        "    min_data_in_leaf = PARAM$FE_rf$datos_por_hoja,\n",
        "    feature_fraction_bynode  = PARAM$FE_rf$mtry_ratio,\n",
        "\n",
        "    # para que LightGBM emule Random Forest\n",
        "    boosting = \"rf\",\n",
        "    bagging_fraction = ( 1.0 - 1.0/exp(1.0) ),\n",
        "    bagging_freq = 1.0,\n",
        "    feature_fraction = 1.0,\n",
        "\n",
        "    # genericos de LightGBM\n",
        "    max_bin = 31L,\n",
        "    objective = \"binary\",\n",
        "    first_metric_only = TRUE,\n",
        "    boost_from_average = TRUE,\n",
        "    feature_pre_filter = FALSE,\n",
        "    force_row_wise = TRUE,\n",
        "    verbosity = -100,\n",
        "    max_depth = -1L,\n",
        "    min_gain_to_split = 0.0,\n",
        "    min_sum_hessian_in_leaf = 0.001,\n",
        "    lambda_l1 = 0.0,\n",
        "    lambda_l2 = 0.0,\n",
        "\n",
        "    pos_bagging_fraction = 1.0,\n",
        "    neg_bagging_fraction = 1.0,\n",
        "    is_unbalance = FALSE,\n",
        "    scale_pos_weight = 1.0,\n",
        "\n",
        "    drop_rate = 0.1,\n",
        "    max_drop = 50,\n",
        "    skip_drop = 0.5,\n",
        "\n",
        "    extra_trees = FALSE\n",
        "  )"
      ],
      "metadata": {
        "id": "i6vcLtXldMpz"
      },
      "id": "i6vcLtXldMpz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering agregando variables de Random Forest\n",
        "AgregaVarRandomForest()"
      ],
      "metadata": {
        "id": "GTTj4VdBezcE"
      },
      "id": "GTTj4VdBezcE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ncol(dataset)\n",
        "colnames(dataset)"
      ],
      "metadata": {
        "id": "bs2vXYFuiXGu"
      },
      "id": "bs2vXYFuiXGu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9.7.1.6  FEhist Reduccion dimensionalidad con canaritos\n",
        "\n",
        "Esta etapa solo se mostrará a la *modalidad Anlista Sr*"
      ],
      "metadata": {
        "id": "l8mKij0XaDY0"
      },
      "id": "l8mKij0XaDY0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de esta etapa NO es mejorar el modelo predictivo"
      ],
      "metadata": {
        "id": "71RWF8n_yVJE"
      },
      "id": "71RWF8n_yVJE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo es eliminar campos poco importantes para hacer espacio a nuevos campos, debido a las restricciones de memoria RAM."
      ],
      "metadata": {
        "id": "PunFy1XWyb66"
      },
      "id": "PunFy1XWyb66"
    },
    {
      "cell_type": "code",
      "source": [
        "VPOS_CORTE <- c()\n",
        "\n",
        "fganancia_lgbm_meseta <- function(probs, datos) {\n",
        "  vlabels <- get_field(datos, \"label\")\n",
        "  vpesos <- get_field(datos, \"weight\")\n",
        "\n",
        "  tbl <- as.data.table(list(\n",
        "    \"prob\" = probs,\n",
        "    \"gan\" = ifelse(vlabels == 1 & vpesos > 1, PARAM$CN$train$gan1, PARAM$CN$train$gan0)\n",
        "  ))\n",
        "\n",
        "  setorder(tbl, -prob)\n",
        "  tbl[, posicion := .I]\n",
        "  tbl[, gan_acum := cumsum(gan)]\n",
        "  setorder(tbl, -gan_acum) # voy por la meseta\n",
        "\n",
        "  gan <- mean(tbl[1:500, gan_acum]) # meseta de tamaño 500\n",
        "\n",
        "  pos_meseta <- tbl[1:500, median(posicion)]\n",
        "  VPOS_CORTE <<- c(VPOS_CORTE, pos_meseta)\n",
        "\n",
        "  return(list(\n",
        "    \"name\" = \"ganancia\",\n",
        "    \"value\" = gan,\n",
        "    \"higher_better\" = TRUE\n",
        "  ))\n",
        "}\n"
      ],
      "metadata": {
        "id": "Ge8rC8iT3bxV"
      },
      "id": "Ge8rC8iT3bxV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimina del dataset las variables que estan por debajo\n",
        "#  de la capa geologica de canaritos\n",
        "# se llama varias veces, luego de agregar muchas variables nuevas,\n",
        "#  para ir reduciendo la cantidad de variables\n",
        "# y así hacer lugar a nuevas variables importantes\n",
        "\n",
        "GVEZ <- 1\n",
        "\n",
        "campitos <- c( \"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\" )\n",
        "\n",
        "CanaritosAsesinos <- function(\n",
        "  canaritos_ratio,\n",
        "  canaritos_desvios,\n",
        "  canaritos_semilla) {\n",
        "\n",
        "  cat( \"inicio CanaritosAsesinos()\\n\")\n",
        "  gc(verbose= FALSE)\n",
        "  dataset[, clase01 := 0L ]\n",
        "  dataset[ clase_ternaria %in% PARAM$CN$train$clase01_valor1,\n",
        "      clase01 := 1L ]\n",
        "\n",
        "  set.seed(canaritos_semilla, kind = \"L'Ecuyer-CMRG\")\n",
        "  for (i in 1:(ncol(dataset) * canaritos_ratio)) {\n",
        "    dataset[, paste0(\"canarito\", i) := runif(nrow(dataset))]\n",
        "  }\n",
        "\n",
        "  campos_buenos <- setdiff(\n",
        "    colnames(dataset),\n",
        "    c( campitos, \"clase01\")\n",
        "  )\n",
        "\n",
        "  azar <- runif(nrow(dataset))\n",
        "\n",
        "  dataset[, entrenamiento :=\n",
        "    as.integer( foto_mes %in% PARAM$CN$train$training &\n",
        "      (clase01 == 1 | azar < PARAM$CN$train$undersampling))]\n",
        "\n",
        "  dtrain <- lgb.Dataset(\n",
        "    data = data.matrix(dataset[entrenamiento == TRUE, campos_buenos, with = FALSE]),\n",
        "    label = dataset[entrenamiento == TRUE, clase01],\n",
        "    weight = dataset[\n",
        "      entrenamiento == TRUE,\n",
        "      ifelse(clase_ternaria %in% PARAM$CN$train$positivos, 1.0000001, 1.0)\n",
        "    ],\n",
        "    free_raw_data = FALSE\n",
        "  )\n",
        "\n",
        "  dvalid <- lgb.Dataset(\n",
        "    data = data.matrix(dataset[foto_mes %in% PARAM$CN$train$validation, campos_buenos, with = FALSE]),\n",
        "    label = dataset[foto_mes %in% PARAM$CN$train$validation, clase01],\n",
        "    weight = dataset[\n",
        "      foto_mes %in% PARAM$CN$train$validation,\n",
        "      ifelse( clase_ternaria %in% PARAM$CN$train$positivos, 1.0000001, 1.0)\n",
        "    ],\n",
        "    free_raw_data = FALSE\n",
        "  )\n",
        "\n",
        "\n",
        "  param <- list(\n",
        "    objective = \"binary\",\n",
        "    metric = \"custom\",\n",
        "    first_metric_only = TRUE,\n",
        "    boost_from_average = TRUE,\n",
        "    feature_pre_filter = FALSE,\n",
        "    verbosity = -100,\n",
        "    seed = canaritos_semilla,\n",
        "    max_depth = -1, # -1 significa no limitar,  por ahora lo dejo fijo\n",
        "    min_gain_to_split = 0.0, # por ahora, lo dejo fijo\n",
        "    lambda_l1 = 0.0, # por ahora, lo dejo fijo\n",
        "    lambda_l2 = 0.0, # por ahora, lo dejo fijo\n",
        "    max_bin = 31, # por ahora, lo dejo fijo\n",
        "    num_iterations = 9999, # un numero grande, lo limita early_stopping_rounds\n",
        "    force_row_wise = TRUE, # para que los alumnos no se atemoricen con  warning\n",
        "    learning_rate = 0.065,\n",
        "    feature_fraction = 1.0, # lo seteo en 1\n",
        "    min_data_in_leaf = 260,\n",
        "    num_leaves = 60,\n",
        "    early_stopping_rounds = 200,\n",
        "    num_threads = 1\n",
        "  )\n",
        "\n",
        "  set.seed(canaritos_semilla, kind = \"L'Ecuyer-CMRG\")\n",
        "  modelo <- lgb.train(\n",
        "    data = dtrain,\n",
        "    valids = list(valid = dvalid),\n",
        "    eval = fganancia_lgbm_meseta,\n",
        "    param = param,\n",
        "    verbose = -100\n",
        "  )\n",
        "\n",
        "  tb_importancia <- lgb.importance(model = modelo)\n",
        "  tb_importancia[, pos := .I]\n",
        "\n",
        "  fwrite(tb_importancia,\n",
        "    file = paste0(\"impo_\", GVEZ, \".txt\"),\n",
        "    sep = \"\\t\"\n",
        "  )\n",
        "\n",
        "  GVEZ <<- GVEZ + 1\n",
        "\n",
        "  umbral <- tb_importancia[\n",
        "    Feature %like% \"canarito\",\n",
        "    median(pos) + canaritos_desvios * sd(pos)\n",
        "  ] # Atencion corto en la mediana mas desvios!!\n",
        "\n",
        "  col_utiles <- tb_importancia[\n",
        "    pos < umbral & !(Feature %like% \"canarito\"),\n",
        "    Feature\n",
        "  ]\n",
        "\n",
        "  col_utiles <- unique(c(\n",
        "    col_utiles,\n",
        "    c(campitos, \"mes\")\n",
        "  ))\n",
        "\n",
        "  col_inutiles <- setdiff(colnames(dataset), col_utiles)\n",
        "\n",
        "  dataset[, (col_inutiles) := NULL]\n",
        "\n",
        "  cat( \"fin CanaritosAsesinos()\\n\")\n",
        "\n",
        "  return( tb_importancia )\n",
        "}\n"
      ],
      "metadata": {
        "id": "bE-g1G6WyqCS"
      },
      "id": "bE-g1G6WyqCS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estos DOS parametros son los que se deben modificar\n",
        "PARAM$CN$ratio <- 0.2\n",
        "PARAM$CN$desvios <- 2\n",
        "\n",
        "\n",
        "# Parametros quasi fijos\n",
        "# Parametros de un LightGBM que se genera para estimar la column importance\n",
        "PARAM$CN$train$clase01_valor1 <- c( \"BAJA+2\", \"BAJA+1\")\n",
        "PARAM$CN$train$positivos <- c( \"BAJA+2\")\n",
        "PARAM$CN$train$training <- c( 202101, 202102, 202103)\n",
        "PARAM$CN$train$validation <- c( 202105 )\n",
        "PARAM$CN$train$undersampling <- 0.1\n",
        "PARAM$CN$train$gan1 <- 117000\n",
        "PARAM$CN$train$gan0 <-  -3000"
      ],
      "metadata": {
        "id": "nrU5TvRozeQ6"
      },
      "id": "nrU5TvRozeQ6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# la llamada a Canaritos Asesinos\n",
        "tb_importancia <- CanaritosAsesinos(\n",
        "  canaritos_ratio = PARAM$CN$ratio,\n",
        "  canaritos_desvios = PARAM$CN$desvios,\n",
        "  canaritos_semilla = PARAM$semilla_primigenia\n",
        ")\n"
      ],
      "metadata": {
        "id": "2EHaQVqZ1Bum"
      },
      "id": "2EHaQVqZ1Bum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo la importancia, ver el archivo directamente en la carpeta\n",
        "\n",
        "fwrite( tb_importancia,\n",
        "  file=\"canaritos.txt\",\n",
        "  sep=\"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "aY89fquP542d"
      },
      "id": "aY89fquP542d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verifico\n",
        "ncol(dataset)\n",
        "colnames(dataset)"
      ],
      "metadata": {
        "id": "qlSs7nBt1SGq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "qlSs7nBt1SGq"
    },
    {
      "cell_type": "markdown",
      "id": "cf91ea5e-3341-4afb-8d05-cc4923d3d1e1",
      "metadata": {
        "id": "cf91ea5e-3341-4afb-8d05-cc4923d3d1e1"
      },
      "source": [
        "### 9.7.2 Modelado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "526048e4-8cf2-4023-bd2d-a70e4e9ff157",
      "metadata": {
        "id": "526048e4-8cf2-4023-bd2d-a70e4e9ff157"
      },
      "source": [
        "#### 9.7.2.1 Training Strategy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16bc1c1-b3ea-43ca-9d3c-53f8f9ab8ec1",
      "metadata": {
        "id": "f16bc1c1-b3ea-43ca-9d3c-53f8f9ab8ec1"
      },
      "source": [
        "Se hace una estrategia de entrenamiento muy sencilla, tomando todos los meses posibles, SIN eliminar nada x pandemia ni por ningun otro motivo\n",
        "\n",
        "* future = 202109  obviamente completo\n",
        "\n",
        "* final_train =  [ 201901, 202107 ] sin undersampling de los CONTINUA\n",
        "\n",
        "* training\n",
        "   * testing = NO HAY\n",
        "   * validation =  202107   completo, sin undersampling\n",
        "   * training = [ 201901, 202105 ]  donde se consideran el 20% de los CONTINUA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c9c0a42-ba58-4264-8566-091a6161716f",
      "metadata": {
        "id": "2c9c0a42-ba58-4264-8566-091a6161716f"
      },
      "outputs": [],
      "source": [
        "PARAM$trainingstrategy$validate <- c(202107)\n",
        "\n",
        "PARAM$trainingstrategy$training <- c(\n",
        "  201901, 201902, 201903, 201904, 201905, 201906,\n",
        "  201907, 201908, 201909, 201910, 201911, 201912,\n",
        "  202001, 202002, 202003, 202004, 202005, 202006,\n",
        "  202007, 202008, 202009, 202010, 202011, 202012,\n",
        "  202101, 202102, 202103, 202104, 202105\n",
        ")\n",
        "\n",
        "PARAM$trainingstrategy$training_pct <- 0.2\n",
        "\n",
        "\n",
        "PARAM$trainingstrategy$positivos <- c( \"BAJA+1\", \"BAJA+2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seteo la clase01   1={BAJA+1, BAJA+2}   0={CONTINUA}\n",
        "dataset[, clase01 := ifelse( clase_ternaria %in% PARAM$trainingstrategy$positivos, 1, 0 )]"
      ],
      "metadata": {
        "id": "tv_trHWAj4a8"
      },
      "id": "tv_trHWAj4a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos en los que se entrena\n",
        "campos_buenos <- copy( setdiff(\n",
        "    colnames(dataset), c(\"clase_ternaria\",\"clase01\",\"azar\"))\n",
        ")"
      ],
      "metadata": {
        "id": "Ud_XDKSIj8f_"
      },
      "id": "Ud_XDKSIj8f_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparo para que se puede hacer undersampling de los CONTINUA\n",
        "#  solamente por un tema de VELOCIDAD\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset[, azar:=runif(nrow(dataset))]\n",
        "\n",
        "# undersampling de los CONTINUA\n",
        "dataset[, fold_train :=  foto_mes %in%  PARAM$trainingstrategy$training &\n",
        "    (clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\") |\n",
        "     azar < PARAM$trainingstrategy$training_pct ) ]\n",
        "\n",
        "\n",
        "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[fold_train == TRUE, campos_buenos, with = FALSE]),\n",
        "  label= dataset[fold_train == TRUE, clase01],\n",
        "  free_raw_data= TRUE\n",
        ")"
      ],
      "metadata": {
        "id": "rFKgZZPSj_Pa"
      },
      "id": "rFKgZZPSj_Pa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datos de validation\n",
        "dvalidate <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[foto_mes %in% PARAM$trainingstrategy$validate, campos_buenos, with = FALSE]),\n",
        "  label= dataset[foto_mes %in% PARAM$trainingstrategy$validate, clase01],\n",
        "  free_raw_data= TRUE\n",
        ")\n",
        "\n",
        "nrow(dvalidate)"
      ],
      "metadata": {
        "id": "B3yo98kQkHcP"
      },
      "id": "B3yo98kQkHcP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "28e8f788-551c-4e50-9029-302ac0834287",
      "metadata": {
        "id": "28e8f788-551c-4e50-9029-302ac0834287"
      },
      "source": [
        "####  9.7.2.2. Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf5fc836-e222-4aeb-a6a8-157346895ef7",
      "metadata": {
        "id": "bf5fc836-e222-4aeb-a6a8-157346895ef7"
      },
      "source": [
        "* Clase binaria que se optimiza :  positivos = [ BAJA+1, BAJA+2 ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "885c03b5-77bc-4510-a930-0d1f14b52ffb",
      "metadata": {
        "id": "885c03b5-77bc-4510-a930-0d1f14b52ffb"
      },
      "source": [
        "* Metrica que se optimiza **AUC** Area Under Curve de la  ROC Curve\n",
        "\n",
        "es muy importante notar que intencionalmente  **NO** se está optimizando la funcion de ganancia del problema"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e6f95c-66ef-4ab9-9ba3-fcc099816704",
      "metadata": {
        "id": "b7e6f95c-66ef-4ab9-9ba3-fcc099816704"
      },
      "source": [
        "* Cantidad de iteraciones inteligentes de la Optimizacion Bayesiana = **10**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe047a87-e2d0-4418-97dd-0a881e66d73a",
      "metadata": {
        "id": "fe047a87-e2d0-4418-97dd-0a881e66d73a"
      },
      "source": [
        "* Parametros no default, fijos de LightGBM que no se optimizan\n",
        "  * max_bin = 31 , Alienigenas Ancestrales contruyeron las pirámides y dejaron a la humanidad en un jeroglifico  *max_bin=31*\n",
        "  * feature_fraction = 0.5  para poner algo que generalmente no falla\n",
        "  * learning_rate = 0.03  para que aprenda lento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7da08e-fe57-4681-beff-11fe963116bd",
      "metadata": {
        "id": "1e7da08e-fe57-4681-beff-11fe963116bd"
      },
      "source": [
        "* Parametros que se optimizan en la Bayesian Optimization\n",
        "  * num_leaves  [8, 256]\n",
        "  * min_data_in_leaf  [8, 8192]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paquetes necesarios para la Bayesian Optimization\n",
        "if(!require(\"DiceKriging\")) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if(!require(\"mlrMBO\")) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ],
      "metadata": {
        "id": "34V6y4GetKq_"
      },
      "id": "34V6y4GetKq_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición de la Bayesian Optimization\n",
        "<br> Si se desea optimizar un hiperparámetro que esta como fijo, debe QUITARSE de param_fijos y agregarse a PARAM$hipeparametertuning$hs"
      ],
      "metadata": {
        "id": "UFbDSYtH0TTT"
      },
      "id": "UFbDSYtH0TTT"
    },
    {
      "cell_type": "code",
      "source": [
        "# 40 es el minimo razonable,  un buen analista Sr aumentara este valor\n",
        "PARAM$hipeparametertuning$num_interations <- 40\n",
        "\n",
        "# parametros fijos del LightGBM\n",
        "PARAM$lgbm$param_fijos <- list(\n",
        "  objective= \"binary\",\n",
        "  metric= \"auc\",\n",
        "  first_metric_only= TRUE,\n",
        "  boost_from_average= TRUE,\n",
        "  feature_pre_filter= FALSE,\n",
        "  verbosity= -100,\n",
        "  force_row_wise= TRUE, # para evitar warning\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "  extra_trees = FALSE,\n",
        "\n",
        "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
        "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
        "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
        "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
        "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
        "\n",
        "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
        "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
        "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  is_unbalance = FALSE, #\n",
        "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
        "\n",
        "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  max_drop = 50, # <=0 means no limit\n",
        "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
        "\n",
        "  max_bin= 31,\n",
        "  num_iterations= 2048,  # valor grande, lo limita early_stopping_rounds\n",
        "  early_stopping_rounds= 200\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "5Uag3XGHqrfZ"
      },
      "id": "5Uag3XGHqrfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevos  pseudo hiperparámetros\n",
        "\n",
        "*   leaf_size (0.0,  0.5]  es el   min_data_in_leaf / nrow(dataset)\n",
        "*   coverage (0.0, 1.0]  se cumple   num_leaves =   coverage * (nrow(dataset)/min_data_in_leaf)\n",
        "\n"
      ],
      "metadata": {
        "id": "0M2oWhHxHc-9"
      },
      "id": "0M2oWhHxHc-9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Notar que se usan los pseudo hiperparametros \"ratio\"  leaf_size  y coverage\n",
        "#  que luego terminan en  min_data_in_leaf y  num_leaves\n",
        "#  de forma que sea invariante al tamaño del dataset\n",
        "\n",
        "PARAM$hipeparametertuning$hs <- makeParamSet(\n",
        "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
        "  makeNumericParam(\"feature_fraction\", lower = 0.05, upper = 0.90),\n",
        "  makeNumericParam(\"coverage\", lower = 0.05, upper = 1.0), # nuevo\n",
        "  makeNumericParam(\"leaf_size\", lower = 0.001, upper = 0.2) # nuevo\n",
        ")"
      ],
      "metadata": {
        "id": "ysYzPjs3CT_a"
      },
      "id": "ysYzPjs3CT_a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función \"señora caja negra\"  que es llamada para verificar la realidad por la Bayesian Optimization"
      ],
      "metadata": {
        "id": "FEa1UuuAz4yj"
      },
      "id": "FEa1UuuAz4yj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c10f535-8d90-47d1-ac3d-9b4c24ec21d2",
      "metadata": {
        "id": "2c10f535-8d90-47d1-ac3d-9b4c24ec21d2"
      },
      "outputs": [],
      "source": [
        "# En  x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en validate del modelo entrenado\n",
        "#  en el parametro x llegan los hiperparámetros que se estan optimizando\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # hago la transformacion de leaf_size y  coverage\n",
        "  if( \"leaf_size\"  %in% names(param_completo) &\n",
        "      \"coverage\"  %in% names(param_completo)\n",
        "  )\n",
        "  {\n",
        "    # primero defino el tamaño de las hojas\n",
        "    param_completo$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_completo$leaf_size )  )\n",
        "    # luego la cantidad de hojas en funcion del valor anterior, el coverage, y la cantidad de registros\n",
        "    param_completo$num_leaves <- pmin( 131072,\n",
        "      pmax( 8,  round( ( param_completo$coverage * nrow( dtrain ) / param_completo$min_data_in_leaf ) ) ))\n",
        "  }\n",
        "\n",
        "  if( \"leaf_size\"  %in% names(param_completo) &\n",
        "      !( \"coverage\"  %in% names(param_completo) )\n",
        "  )\n",
        "  {\n",
        "    # primero defino el tamaño de las hojas\n",
        "    param_completo$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_completo$leaf_size )  )\n",
        "  }\n",
        "\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelo_train <- lgb.train(\n",
        "    data= dtrain,\n",
        "    valids= list(valid = dvalidate),\n",
        "    eval= \"auc\",\n",
        "    param= param_completo,\n",
        "    verbose= -100\n",
        "  )\n",
        "\n",
        "  # recupero la AUC en validation\n",
        "  AUC <- modelo_train$record_evals$valid$auc$eval[[modelo_train$best_iter]]\n",
        "\n",
        "  # esta es la forma de devolver un parametro extra\n",
        "  attr(AUC, \"extras\") <- list(\"num_iterations\"= modelo_train$best_iter)\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelo_train)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "267a35d4-adaf-4271-a875-3864111333b7",
      "metadata": {
        "id": "267a35d4-adaf-4271-a875-3864111333b7"
      },
      "source": [
        "seteo de la Bayesian Optimization (complejo)\n",
        "<br> copiado y pegado de la documentación de la librería"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43c2a92d-1041-46b8-bff2-47297f209ed2",
      "metadata": {
        "id": "43c2a92d-1041-46b8-bff2-47297f209ed2"
      },
      "outputs": [],
      "source": [
        "configureMlr(show.learner.output = FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "    fn= EstimarGanancia_AUC_lightgbm, # la funcion que voy a maximizar\n",
        "    minimize= FALSE, # estoy Maximizando AUC\n",
        "    noisy= FALSE,\n",
        "    par.set= PARAM$hipeparametertuning$hs,\n",
        "    has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "    save.on.disk.at.time= 600,\n",
        "    save.file.path= \"HT.RDATA\"\n",
        ")\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "    ctrl,\n",
        "    iters= PARAM$hipeparametertuning$num_interations  # cantidad de iteraciones inteligentes\n",
        ")\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales\n",
        "#   los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
        "\n",
        "# mas configuraciones\n",
        "surr.km <- makeLearner(\n",
        "    \"regr.km\",\n",
        "    predict.type= \"se\",\n",
        "    covtype= \"matern3_2\",\n",
        "    control= list(trace = TRUE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c1e5645-d26f-4923-a53f-f30471a4c4e8",
      "metadata": {
        "id": "6c1e5645-d26f-4923-a53f-f30471a4c4e8"
      },
      "source": [
        "Corrida de la Bayesian Optimization,  aqui se hace el trabajo pesado\n",
        "<br> por favor no se asuste con los warnings que pudieran aparecer\n",
        "\n",
        "Si corrío a medias y llegó a las iteraciones inteligentes, en el archivo binario HT.RDATA quedó lo ya procesado y es utilizado para retomar la corrida desde lo último que llegó a grabar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f8cab3f-c7e2-4802-bfd1-5ad509922a4e",
      "metadata": {
        "scrolled": true,
        "id": "1f8cab3f-c7e2-4802-bfd1-5ad509922a4e"
      },
      "outputs": [],
      "source": [
        "# inicio la optimizacion bayesiana\n",
        "\n",
        "if (!file.exists(\"HT.RDATA\")) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(\"HT.RDATA\") # retomo en caso que ya exista\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36307612-964f-4df3-907a-1bc3c095f178",
      "metadata": {
        "id": "36307612-964f-4df3-907a-1bc3c095f178"
      },
      "source": [
        "la bayesian optimization ha corrido, extraigo los mejores hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c061a2a-3341-4006-a154-c95bb6cfd407",
      "metadata": {
        "id": "8c061a2a-3341-4006-a154-c95bb6cfd407"
      },
      "outputs": [],
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y, -num_iterations)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file=\"BO_log.txt\",\n",
        "  sep=\"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  list(learning_rate, feature_fraction, coverage, leaf_size)\n",
        "]\n",
        "\n",
        "print(PARAM$out$lgbm$mejores_hiperparametros)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddb554cb-1d96-4f6b-ae1c-c9a076f8dbdc",
      "metadata": {
        "id": "ddb554cb-1d96-4f6b-ae1c-c9a076f8dbdc"
      },
      "source": [
        "### 9.7.3 Produccion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c39492c3-756f-47a5-8747-93ade8275306",
      "metadata": {
        "id": "c39492c3-756f-47a5-8747-93ade8275306"
      },
      "source": [
        "#### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
      ],
      "metadata": {
        "id": "xhKi_G_sYQqq"
      },
      "id": "xhKi_G_sYQqq"
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$trainingstrategy$final_train <- c(\n",
        "  201901, 201902, 201903, 201904, 201905, 201906,\n",
        "  201907, 201908, 201909, 201910, 201911, 201912,\n",
        "  202001, 202002, 202003, 202004, 202005, 202006,\n",
        "  202007, 202008, 202009, 202010, 202011, 202012,\n",
        "  202101, 202102, 202103, 202104, 202105, 202106,\n",
        "  202107\n",
        ")\n",
        "\n",
        "dataset[, fold_final_train := foto_mes %in% PARAM$trainingstrategy$final_train ]\n",
        "\n",
        "# creo el dfinal_train en formato  LightGBM\n",
        "dfinal_train <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[fold_final_train == TRUE, campos_buenos, with= FALSE]),\n",
        "  label= dataset[fold_final_train == TRUE, clase01],\n",
        "  free_raw_data= TRUE\n",
        ")\n",
        "\n",
        "nrow( dfinal_train) # verifico el tamaño"
      ],
      "metadata": {
        "id": "qyHfS_X0zd7o"
      },
      "id": "qyHfS_X0zd7o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final Training Hyperparameters"
      ],
      "metadata": {
        "id": "HATRyklxYUpT"
      },
      "id": "HATRyklxYUpT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b9f33c-e0a0-4ea6-8169-4a6180cc5d01",
      "metadata": {
        "id": "d6b9f33c-e0a0-4ea6-8169-4a6180cc5d01"
      },
      "outputs": [],
      "source": [
        "# uno los parametros fijos y los mejores encontrados de los variables\n",
        "fijos <- copy(PARAM$lgbm$param_fijos)\n",
        "\n",
        "# quito lo que optimice en la Bayesian Optimization\n",
        "fijos$num_iterations <- NULL\n",
        "fijos$early_stopping_rounds <- NULL\n",
        "\n",
        "# agrego a los hiperparametros fijos los que encontre con la Bayesian Optimization\n",
        "param_final <- c(fijos, PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "# hago la transformacion de leaf_size y  coverage\n",
        "  if( \"leaf_size\"  %in% names(param_final) &\n",
        "      \"coverage\"  %in% names(param_final)\n",
        "  )\n",
        "  {\n",
        "    # primero defino el tamaño de las hojas\n",
        "    param_final$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_final$leaf_size )  )\n",
        "    # luego la cantidad de hojas en funcion del valor anterior, el coverage, y la cantidad de registros\n",
        "    param_final$num_leaves <- pmin( 131072,\n",
        "      pmax( 8,  round( ( param_final$coverage * nrow( dtrain ) / param_final$min_data_in_leaf ) ) ))\n",
        "  }\n",
        "\n",
        "  if( \"leaf_size\"  %in% names(param_final) &\n",
        "      !( \"coverage\"  %in% names(param_final) )\n",
        "  )\n",
        "  {\n",
        "    # primero defino el tamaño de las hojas\n",
        "    param_final$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_final$leaf_size )  )\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_final"
      ],
      "metadata": {
        "id": "5Y2WIAWbYc1C"
      },
      "id": "5Y2WIAWbYc1C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "05d3494f-0401-4f3e-9b69-f488a737879d",
      "metadata": {
        "id": "05d3494f-0401-4f3e-9b69-f488a737879d"
      },
      "source": [
        "##### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$FT$semillerio <- 20  # cantidad de semillas"
      ],
      "metadata": {
        "id": "HhvnAhuxdXWq"
      },
      "id": "HhvnAhuxdXWq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(!require(\"primes\")) install.packages(\"primes\")\n",
        "require(\"primes\")"
      ],
      "metadata": {
        "id": "tcYH_MiJdeEs"
      },
      "id": "tcYH_MiJdeEs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "primos <- generate_primes(min = 100000, max = 1000000)\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "# me quedo con PARAM$semillerio  primos al azar\n",
        "PARAM$FT$semillas <- sample(primos)[seq(PARAM$FT$semillerio)]\n",
        "\n",
        "cat( PARAM$FT$semillas)"
      ],
      "metadata": {
        "id": "weEzmJf5fiog"
      },
      "id": "weEzmJf5fiog",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa239848-1c28-4ee5-984a-073903b4b279",
      "metadata": {
        "id": "fa239848-1c28-4ee5-984a-073903b4b279"
      },
      "outputs": [],
      "source": [
        "dir.create(\"modelos\", showWarnings =FALSE)\n",
        "\n",
        "primero <- TRUE\n",
        "for( sem in PARAM$FT$semillas)\n",
        "{\n",
        "  nombre_arch <- paste0( \"./modelos/modelo_\", sem, \".txt\")\n",
        "  if( !file.exists(nombre_arch) )\n",
        "  {\n",
        "    param_final$seed <- sem\n",
        "\n",
        "    set.seed(sem, kind = \"L'Ecuyer-CMRG\")\n",
        "    final_model <- lgb.train(\n",
        "      data= dfinal_train,\n",
        "      param= param_final,\n",
        "      verbose= -100\n",
        "    )\n",
        "\n",
        "    lgb.save(final_model, nombre_arch) # grabo el modelo\"\n",
        "\n",
        "    # grabo la primer importancia de variables\n",
        "    #  Natalia : da lo mismo cual se guarda\n",
        "    if( primero)\n",
        "    {\n",
        "      primero <- FALSE\n",
        "      tb_importancia <- as.data.table(lgb.importance(final_model))\n",
        "      archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "      fwrite( tb_importancia,\n",
        "        file= archivo_importancia,\n",
        "        sep= \"\\t\"\n",
        "      )\n",
        "    }\n",
        " }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea225b3-ce02-42e2-8330-b10ed250d172",
      "metadata": {
        "id": "7ea225b3-ce02-42e2-8330-b10ed250d172"
      },
      "source": [
        "#### Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "164981bb-f4c1-4228-8bc9-32e58a383c05",
      "metadata": {
        "id": "164981bb-f4c1-4228-8bc9-32e58a383c05"
      },
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$trainingstrategy$future <- c(202109)\n",
        "\n",
        "dfuture <- dataset[ foto_mes %in% PARAM$trainingstrategy$future ]"
      ],
      "metadata": {
        "id": "eJ7RbT271v-R"
      },
      "id": "eJ7RbT271v-R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ca61c8-fa24-4ce5-8be1-323aca018e8f",
      "metadata": {
        "id": "88ca61c8-fa24-4ce5-8be1-323aca018e8f"
      },
      "outputs": [],
      "source": [
        "# aplico final_model   a dfuture\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := 0]\n",
        "\n",
        "datos_matrix <- data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        "\n",
        "\n",
        "for( isem in seq(length(PARAM$FT$semillas)) )\n",
        "{\n",
        "   sem <- PARAM$FT$semillas[ isem ]\n",
        "   nombre_arch <- paste0( \"./modelos/modelo_\", sem, \".txt\")\n",
        "   final_model <- lgb.load(nombre_arch)\n",
        "\n",
        "   prediccion <- predict(\n",
        "     final_model,\n",
        "     datos_matrix\n",
        "  )\n",
        "\n",
        "  tb_prediccion[, paste0(\"prob_\", isem) := prediccion]\n",
        "  tb_prediccion[, prob := prob + prediccion]\n",
        "\n",
        "  rm(final_model)\n",
        "  rm(prediccion)\n",
        "  gc(full = TRUE, verbose=FALSE)\n",
        "}\n",
        "\n",
        "rm( datos_matrix)\n",
        "gc(full = TRUE, verbose=FALSE)\n",
        "\n",
        "tb_prediccion[, prob := prob /length(PARAM$FT$semillas) ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veo que hay en tb_prediccion\n",
        "tb_prediccion"
      ],
      "metadata": {
        "id": "Q10qYVKNqqte"
      },
      "id": "Q10qYVKNqqte",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo las probabilidad del modelo\n",
        "#  me va a ser util para hacer Ensembles de modelos\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "TB6aerGDZeTo"
      },
      "id": "TB6aerGDZeTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8412d838-5bd5-454e-b3a9-5eaa18d80a50",
      "metadata": {
        "id": "8412d838-5bd5-454e-b3a9-5eaa18d80a50"
      },
      "source": [
        "#### Kaggle Competition Submit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55970cb6-856a-46e3-a893-7f36b8352b8e",
      "metadata": {
        "id": "55970cb6-856a-46e3-a893-7f36b8352b8e"
      },
      "source": [
        "Genero las salidas y hago los submits a Kaggles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5fa2439-b0e9-49e0-a861-71d7315d6e1c",
      "metadata": {
        "id": "e5fa2439-b0e9-49e0-a861-71d7315d6e1c"
      },
      "outputs": [],
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-b\"\n",
        "PARAM$kaggle$cortes <- seq(10000, 12000, by = 500)\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$kaggle$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\n",
        "    \"./kaggle/KA\",\n",
        "    PARAM$experimento, \"_\",\n",
        "    \"s\", length(PARAM$FT$semillas), \"_\",\n",
        "    envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  # subida a Kaggle, armo la linea de comando\n",
        "  comando <- \"kaggle competitions submit\"\n",
        "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
        "  arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
        "  \"  semilla=\", PARAM$semilla_primigenia,\n",
        "    \"'\" )\n",
        "\n",
        "  linea <- paste( comando, competencia, arch, mensaje)\n",
        "\n",
        "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
        "  cat(salida, \"\\n\")\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo los parametros\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ],
      "metadata": {
        "id": "C94tK-xid6p2"
      },
      "id": "C94tK-xid6p2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb",
      "metadata": {
        "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb"
      },
      "outputs": [],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}