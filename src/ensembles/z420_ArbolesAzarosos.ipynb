{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Ensembles de Arboles de Decision"
      ],
      "metadata": {
        "id": "kgJ0E--L0n9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un arbol de decisión es un modelo débil, el aumento del poder predictivo proviene al ensamblar varios arboles de decisión.\n",
        "<br> Si promedio n arboles identicos, el resultados es exactamente el mismo que utilizar un solo arbol, necesito PERTURBAR cada arbol para disponer de variablidad"
      ],
      "metadata": {
        "id": "PgLdmWznXWGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "la variabilidad provendrá de estas fuentes:\n",
        "\n",
        "\n",
        "*   Perturbar el dataset\n",
        "*   Perturbar el algoritmo del arbol\n",
        "*   Perturbar el dataset y el algoritmo del arbol al mismo tiempo"
      ],
      "metadata": {
        "id": "FTnxMEOqYRXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se verán estos tres algoritmos\n",
        "\n",
        "\n",
        "*   Arboles Azarosos\n",
        "*   Random Forest\n",
        "*   Gradient Boosting of Decision Trees"
      ],
      "metadata": {
        "id": "DHp1h9m-X7Rc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m0ySYPfa7Zr"
      },
      "source": [
        "#### 4.01 Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs"
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/dm\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc9x9DnsNlZv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.02 Arboles Azarosos"
      ],
      "metadata": {
        "id": "qq0KVOtq1K5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arboles Azarosos es el nombre de un algoritmo trivial (por favor NO confundir con Random Forest)\n",
        "Qué tipo de perturbaciones se realizan en Arboles Azarosos\n",
        "* Se perturba el dataset\n",
        "* No se perturba el algoritmo, es siempre rpart original"
      ],
      "metadata": {
        "id": "HsNJjhlRo9jM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada  arbolito de  Arboles Azarosos se entrena sobre un dataset perturbado,  que tiene exactamente la misma cantidad de registros pero solo un subconjunto de los atributos (campos)  del dataset, tomados al azar, de los originales.\n",
        "<br> En esta primera corrida, se construira cada arbol en un dataset utilizando el 50% de los campos"
      ],
      "metadata": {
        "id": "rq2HC28CpXBR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8dySimCPRT"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "LrdtraBYJrsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iE0U4_WCPRT"
      },
      "outputs": [],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJDwdD0dCPRU"
      },
      "outputs": [],
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui debe cargar SU semilla primigenia"
      ],
      "metadata": {
        "id": "M8-Pyp6CCPRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$semilla_primigenia <- 102191\n",
        "\n",
        "# parametros  arbol\n",
        "# entreno cada arbol con solo 50% de las variables variables\n",
        "#  por ahora, es fijo\n",
        "PARAM$feature_fraction <- 0.5\n",
        "\n",
        "PARAM$rpart$cp <- -1\n",
        "PARAM$rpart$minsplit <- 50\n",
        "PARAM$rpart$minbucket <- 20\n",
        "PARAM$rpart$maxdepth <- 6\n",
        "\n",
        "# voy a generar 512 arboles,\n",
        "#  a mas arboles mas tiempo de proceso y MEJOR MODELO,\n",
        "#  pero ganancias marginales\n",
        "PARAM$num_trees_max <- 512"
      ],
      "metadata": {
        "id": "peRH7ySLCPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- \"exp4020\"\n",
        "dir.create(experimento, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ],
      "metadata": {
        "id": "1gZD6ZMvCPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ],
      "metadata": {
        "id": "Xi0emX2ECPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defino los dataset de entrenamiento y aplicacion\n",
        "dtrain <- dataset[foto_mes == 202107]\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# arreglo clase_ternaria por algun distraido \"\"\n",
        "dfuture[, clase_ternaria := NA ]"
      ],
      "metadata": {
        "id": "RA3cSJ6KaGwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establezco cuales son los campos que puedo usar para la prediccion\n",
        "# el copy() es por la Lazy Evaluation\n",
        "campos_buenos <- copy(setdiff(colnames(dtrain), c(\"clase_ternaria\")))"
      ],
      "metadata": {
        "id": "EByLkVMwaC8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# que tamanos de ensemble grabo a disco\n",
        "grabar <- c(1, 2, 4, 8, 16, 32, 64, 128, 256, 384, 512)"
      ],
      "metadata": {
        "id": "rHMrHwwpaB8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "# aqui se va acumulando la probabilidad del ensemble\n",
        "tb_prediccion[, prob_acumulada := 0]"
      ],
      "metadata": {
        "id": "bJHS2aeghw6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(PARAM$semilla_primigenia) # Establezco la semilla aleatoria"
      ],
      "metadata": {
        "id": "H_DGUB_fhzHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (arbolito in seq(PARAM$num_trees_max) ) {\n",
        "  message( arbolito, \" \")\n",
        "  qty_campos_a_utilizar <- as.integer(length(campos_buenos)\n",
        "    * PARAM$feature_fraction)\n",
        "\n",
        "  # elijo los campos al azar\n",
        "  campos_random <- sample(campos_buenos, qty_campos_a_utilizar)\n",
        "\n",
        "  # paso de un vector a un string con los elementos\n",
        "  # separados por un signo de \"+\"\n",
        "  # este hace falta para la formula\n",
        "  campos_random <- paste(campos_random, collapse= \" + \")\n",
        "\n",
        "  # armo la formula para rpart\n",
        "  formulita <- paste0(\"clase_ternaria ~ \", campos_random)\n",
        "\n",
        "  # genero el arbol de decision\n",
        "  modelo <- rpart(formulita,\n",
        "    data= dtrain,\n",
        "    xval= 0,\n",
        "    control= PARAM$rpart\n",
        "  )\n",
        "\n",
        "  # aplico el modelo a los datos que no tienen clase\n",
        "  prediccion <- predict(modelo, dfuture, type= \"prob\")\n",
        "\n",
        "  tb_prediccion[, prob_acumulada := prob_acumulada + prediccion[, \"BAJA+2\"]]\n",
        "\n",
        "  if (arbolito %in% grabar) {\n",
        "    umbral_corte <- (1 / 40) * arbolito\n",
        "    tb_prediccion[, Predicted := as.numeric(prob_acumulada > umbral_corte)]\n",
        "\n",
        "    archivo_kaggle <- paste0(\n",
        "        \"KA420_\",\n",
        "        sprintf(\"%.3d\", arbolito), # para que tenga ceros adelante\n",
        "        \".csv\"\n",
        "      )\n",
        "\n",
        "    # grabo el archivo\n",
        "    fwrite( tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "      file= archivo_kaggle,\n",
        "      sep= \",\"\n",
        "    )\n",
        "\n",
        "    # subida a Kaggle\n",
        "    comando <- \"kaggle competitions submit\"\n",
        "    competencia <- \"-c data-mining-analista-sr-2025-b\"\n",
        "    arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "    mensaje <- paste0(\"-m 'cp=\", PARAM$rpart$cp, \"  minsplit=\", PARAM$rpart$minsplit, \"  minbucket=\", PARAM$rpart$minbucket, \" maxdepth=\", PARAM$rpart$maxdepth, \"'\" )\n",
        "    linea <- paste( comando, competencia, arch, mensaje)\n",
        "    salida <- system(linea, intern=TRUE)\n",
        "    cat(salida)\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "j-xp2HQDhFmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "lgmvRHcfJpls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMr6Z1enOyd3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}